{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a061ffc0-21fb-4f10-857b-ca293887cc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import json\n",
    "from typing import Union\n",
    "import numpy as np\n",
    "import itertools\n",
    "from disagreement import Disagreement\n",
    "import joblib\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15b2d91f-2f2a-4f20-9b17-ed2b46eb80ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from compactor.MaxNonActivatedCompactor import MaxNonActivatedCompactor\n",
    "from compactor.ActivatedCompactor import ActivatedCompactor\n",
    "from compactor.MaxCompactor import MaxCompactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b752c83-85f8-405e-82ec-ddeaffb19016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_prediction_fold_1_2016-01-07.csv\n",
      "test_prediction_fold_2_2015-09-09.csv\n",
      "test_prediction_fold_3_2015-05-12.csv\n",
      "test_prediction_fold_4_2015-01-12.csv\n",
      "test_prediction_fold_5_2014-09-14.csv\n",
      "test_prediction_fold_6_2014-05-17.csv\n",
      "xgb_classifier_t_200_md_10_lr_0.1_fold_1_2016-01-07.sav\n",
      "xgb_classifier_t_200_md_10_lr_0.1_fold_2_2015-09-09.sav\n",
      "xgb_classifier_t_200_md_10_lr_0.1_fold_3_2015-05-12.sav\n",
      "xgb_classifier_t_200_md_10_lr_0.1_fold_4_2015-01-12.sav\n",
      "xgb_classifier_t_200_md_10_lr_0.1_fold_5_2014-09-14.sav\n",
      "xgb_classifier_t_200_md_10_lr_0.1_fold_6_2014-05-17.sav\n"
     ]
    }
   ],
   "source": [
    "!ls /storage/scratch/e17-fyp-xai/projects/e17-4yp-using-machine-learning-in-high-stake-settings/code/new/model_outputs/artifacts/xgb_classifier_t_200_md_10_lr_0.1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67dc1146-fd99-4f9b-8624-12173aff92c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/storage/scratch/e17-fyp-xai/projects/e17-4yp-using-machine-learning-in-high-stake-settings/code/new/model_outputs/\"\n",
    "model_path = \"xgb_classifier_t_200_md_10_lr_0.1/\" # Change\n",
    "model_name = \"xgb_classifier_t_200_md_10_lr_0.1_fold_4_2015-01-12.sav\" # Change\n",
    "xai_root = root + \"xai/2024/\"\n",
    "art_root = root + \"artifacts/\"\n",
    "analysis_path = root + \"analysis/2024/\"\n",
    "json_file_path = xai_root + model_path + \"all_exp.json\"\n",
    "processed_data_path = \"/storage/scratch/e17-fyp-xai/projects/e17-4yp-using-machine-learning-in-high-stake-settings/code/processed_data/processed_final_data_latest.csv\"\n",
    "\n",
    "fold = 'fold4' # Change\n",
    "model_type = 'xgb' # Types: nn, xgb, lgbm, lr, rf # Change\n",
    "\n",
    "model_type_save = 'XGB'\n",
    "\n",
    "save_path = analysis_path + model_path + f\"agreement_levels_all_explanations/{fold}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cac614b9-6fab-4156-8ae7-7c80cd53c70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change directory and import\n",
    "os.chdir(\"/storage/scratch/e17-fyp-xai/projects/mad_v3/e17-4yp-using-machine-learning-in-high-stake-settings/code/\")\n",
    "import config\n",
    "categorical_cols = config.CATEGORICAL_COLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d482c97d-3688-4fd0-9b9f-873218199d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "# Function to save images\n",
    "def save_image(caption, path):\n",
    "    set_path = f'{path}/{caption}.png'\n",
    "    plt.savefig(set_path)\n",
    "\n",
    "def make_directory(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f0512fe-10ae-415f-8326-e8ce298993f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_directory(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c548d4d6-f3f8-4303-8bd7-79fa58b77e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Project ID', 'Project Posted Date', 'Project Type',\n",
       "       'Project Posted Month', 'Project Subject Category Tree', 'Project Cost',\n",
       "       'Project Subject Subcategory Tree', 'Project Grade Level Category',\n",
       "       'Project Resource Category', 'School Metro Type', 'School State',\n",
       "       'Teacher Project Posted Sequence', 'Label', 'Teacher Success Rate',\n",
       "       'Teacher Success Rate Imputed', 'School City Success Rate',\n",
       "       'School City Success Rate Imputed', 'School Success Rate',\n",
       "       'School Success Rate Imputed', 'School County Success Rate',\n",
       "       'School County Success Rate Imputed', 'Project Count in State',\n",
       "       'Project Need Statement Length', 'School City',\n",
       "       'Project Need Statement', 'Resource Vendor Name', 'Teacher Prefix',\n",
       "       'Project Short Description Length', 'School County',\n",
       "       'Project Count in County', 'Project Title', 'Project Essay',\n",
       "       'Resource Cost Percentage', 'Project Essay Length',\n",
       "       'School Percentage Free Lunch', 'Resource Cost',\n",
       "       'Resource Cost Imputed', 'Project Count in City',\n",
       "       'Project Short Description', 'School Percentage Free Lunch Imputed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read dataframe to get actual label and for the categorical columns\n",
    "processed = pd.read_csv(processed_data_path)\n",
    "processed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72745667-81ad-4828-a500-d75257a1c84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load explanations\n",
    "explanations = json.load(open(json_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adf56391-2b8d-40ca-a70a-926068adf1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lime_fs_auto_sai_True_nums_1000', 'lime_fs_auto_sai_False_nums_5000', 'treeshap_alg_auto_tr_None', 'treeshap_alg_deep_tr_100']\n"
     ]
    }
   ],
   "source": [
    "xai_keys_list = list(explanations[fold].keys())\n",
    "print(xai_keys_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "876f7d7a-029a-43f8-908c-ddb4fd9e64ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 122 3 6\n"
     ]
    }
   ],
   "source": [
    "# Set n features values\n",
    "top_keys = list(explanations[fold][xai_keys_list[0]]['top'].keys())\n",
    "bottom_keys = list(explanations[fold][xai_keys_list[0]]['bottom'].keys())\n",
    "top_10_perc_uncompressed = round(len(explanations[fold][xai_keys_list[0]]['top'][top_keys[0]])* 0.1) \n",
    "top_20_perc_uncompressed = round(len(explanations[fold][xai_keys_list[0]]['top'][top_keys[0]])* 0.2)\n",
    "top_10_perc_compressed = round(31* 0.1) \n",
    "top_20_perc_compressed = round(31* 0.2)\n",
    "print(top_10_perc_uncompressed, top_20_perc_uncompressed, top_10_perc_compressed, top_20_perc_compressed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fe6a5431-c87c-4d79-a5bb-d752a22bc1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disagreement_average(explanations1: dict, explanations2: dict, both_local: bool, k: int, features_F: list, method = None, raw_data = None, debug = False) -> dict:\n",
    "    \n",
    "    disagreement_mean = {'feature_agreement': 0.0,\n",
    "                         'rank_agreement': 0.0,\n",
    "                         'sign_agreement': 0.0,\n",
    "                         'signed_rank_agreement': 0.0}\n",
    "\n",
    "    # explanations_1 is always local\n",
    "    # explanations_2 can either be local or global\n",
    "    \n",
    "    for project_id in explanations1.keys():\n",
    "        if debug:\n",
    "            print(f\"******************Project ID: {project_id}************************\")\n",
    "        \n",
    "        disagreement_calc = None\n",
    "\n",
    "       \n",
    "        # Initialize disagreement calculation\n",
    "        if both_local:\n",
    "            disagreement_calc = Disagreement(explanations1[project_id], explanations2[project_id])\n",
    "        else:\n",
    "            disagreement_calc = Disagreement(explanations2, explanations1[project_id])\n",
    "        \n",
    "        if debug:\n",
    "            print(\"Initial Explanation 1 \\n\", disagreement_calc.sorted_explanation1[:k])\n",
    "            print(\"Initial Explanation 2 \\n\", disagreement_calc.sorted_explanation2[:k])\n",
    "            \n",
    "        if method==\"max\":\n",
    "            max_compactor = MaxCompactor(categorical_cols)\n",
    "            disagreement_calc.compact_features(max_compactor)\n",
    "            \n",
    "            \n",
    "        elif method == \"activated\" and raw_data is not None:\n",
    "            activated_features = {}\n",
    "            for feature in categorical_cols:\n",
    "                sub_feature = raw_data[raw_data['Project ID'] == project_id ][feature].values[0]\n",
    "                \n",
    "                if model_type=='xgb':\n",
    "                    sub_feature = re.sub(r'[&!@,\\)\\(]', '', sub_feature)\n",
    "\n",
    "                activated_features[feature] = f\"{feature}_{sub_feature}\"\n",
    "\n",
    "            activated_compactor = ActivatedCompactor(activated_features)\n",
    "            disagreement_calc.compact_features(activated_compactor)\n",
    "            \n",
    "        elif method == \"maxnonactivated\" and raw_data is not None:\n",
    "            activated_features = {}\n",
    "            for feature in categorical_cols:\n",
    "                sub_feature = raw_data[raw_data['Project ID'] == project_id ][feature].values[0]\n",
    "                \n",
    "                if model_type=='xgb':\n",
    "                    sub_feature = re.sub(r'[&!@,\\)\\(]', '', sub_feature)\n",
    "\n",
    "                activated_features[feature] = f\"{feature}_{sub_feature}\"\n",
    "            max_non_activated_compactor = MaxNonActivatedCompactor(activated_features)\n",
    "            disagreement_calc.compact_features(max_non_activated_compactor)\n",
    "            \n",
    "        if debug:\n",
    "            print(\"After Compact Explanation 1 \\n\",disagreement_calc.sorted_explanation1[:k])\n",
    "            print(\"After Compact Explanation 2 \\n\",disagreement_calc.sorted_explanation2[:k])\n",
    "            \n",
    "            \n",
    "        disagreement = disagreement_calc.get_disagreement(k, features_F)\n",
    "        \n",
    "        if debug:\n",
    "            print(\"Disagreement : \", disagreement)\n",
    "        \n",
    "        for key in list(disagreement_mean.keys()):\n",
    "            if disagreement[key] == None:\n",
    "                raise ValueError(f\"The value for key '{key}' in disagreement_mean is None.\")\n",
    "            disagreement_mean[key] += disagreement[key]\n",
    "        \n",
    "        if debug:\n",
    "            print(\"****************************************\")\n",
    "\n",
    "    for key in list(disagreement_mean.keys()):\n",
    "        disagreement_mean[key] = round(disagreement_mean[key] / len(explanations1.keys()),3)\n",
    "    \n",
    "    if debug:\n",
    "        print(\"*********************************************\")\n",
    "        print(disagreement_mean)\n",
    "        print(\"*********************************************\")\n",
    "\n",
    "    \n",
    "    return disagreement_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6780f2e2-349a-4895-9c04-981b86946068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_feat(model_path, model_name, model_type):\n",
    "    # Load the model\n",
    "    model = None\n",
    "    importance = None\n",
    "    feat_names = None\n",
    "    \n",
    "    if model_type == 'nn':\n",
    "        model_file_path = f'{model_path}{model_name}' \n",
    "        model = keras.models.load_model(model_file_path)\n",
    "        # Skip the rest\n",
    "\n",
    "    elif model_type == 'lgbm':\n",
    "        model_file_path = f'{model_path}{model_name}'\n",
    "        model = joblib.load(model_file_path)\n",
    "        # Load the feature importance array\n",
    "        importance = model.feature_importances_\n",
    "        # Get the feature names\n",
    "        feat_names = model.feature_name_\n",
    "\n",
    "    elif model_type == 'lr':\n",
    "        model_file_path = f'{model_path}{model_name}'\n",
    "        model = joblib.load(model_file_path)\n",
    "        # Load the feature importance array\n",
    "        importance = model.coef_[0]\n",
    "        # Get the feature names\n",
    "        feat_names = model.feature_names_in_\n",
    "    \n",
    "    else:\n",
    "        model_file_path = f'{model_path}{model_name}'\n",
    "        model = joblib.load(model_file_path)\n",
    "        # Load the feature importance array\n",
    "        importance = model.feature_importances_\n",
    "        # Get the feature names\n",
    "        feat_names = model.feature_names_in_\n",
    "    \n",
    "    return importance, feat_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32a40580-f0b5-4ccd-8209-cefd30559231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to select the top k features and plot\n",
    "def select_top_features(importance, feat_names):\n",
    "    # Create df and sort\n",
    "    df = pd.DataFrame({\"Feature\": feat_names, \"Importance\": importance})\n",
    "    #df_sorted = df.sort_values(\"Importance\", ascending=False)\n",
    "    df_sorted = df.reindex(df.Importance.abs().sort_values(ascending=False).index)\n",
    "    return df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95143e09-79a6-454a-9843-379d5c8b2c0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Feature  Importance\n",
      "563                                School State_Oregon    0.011581\n",
      "557                            School State_New Mexico    0.010491\n",
      "564                          School State_Pennsylvania    0.009730\n",
      "547                         School State_Massachusetts    0.009542\n",
      "1                                         Project Cost    0.009128\n",
      "..                                                 ...         ...\n",
      "272  Project Subject Subcategory Tree_Economics Nut...    0.000000\n",
      "271   Project Subject Subcategory Tree_Economics Music    0.000000\n",
      "270  Project Subject Subcategory Tree_Economics Mat...    0.000000\n",
      "269  Project Subject Subcategory Tree_Economics Lit...    0.000000\n",
      "304  Project Subject Subcategory Tree_Extracurricul...    0.000000\n",
      "\n",
      "[608 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/e17296/miniconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [20:08:16] WARNING: /workspace/src/common/error_msg.h:80: If you are loading a serialized model (like pickle in Python, RDS in R) or\n",
      "configuration generated by an older version of XGBoost, please export the model by calling\n",
      "`Booster.save_model` from that version first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/stable/tutorials/saving_model.html\n",
      "\n",
      "for more details about differences between saving model and serializing.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "global_importance, feat_names = load_model_and_feat(art_root+model_path, model_name, model_type)\n",
    "#print(global_importance, feat_names)\n",
    "global_explanation = select_top_features(global_importance, feat_names)\n",
    "print(global_explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49ee716a-a464-4b36-959f-51b3de590e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['School State_Oregon' 0.011580866761505604]\n",
      " ['School State_New Mexico' 0.01049087941646576]\n",
      " ['School State_Pennsylvania' 0.009729629382491112]\n",
      " ...\n",
      " ['Project Subject Subcategory Tree_Economics Mathematics' 0.0]\n",
      " ['Project Subject Subcategory Tree_Economics Literature  Writing' 0.0]\n",
      " ['Project Subject Subcategory Tree_Extracurricular Gym  Fitness' 0.0]]\n"
     ]
    }
   ],
   "source": [
    "print(global_explanation.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9f1b715-7fd1-415c-8657-7143fe94aeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty df - define the column names\n",
    "df = pd.DataFrame(columns=['Explanations', 'Compactor', 'Model', \n",
    "                           'Feature(10%)', 'Feature(20%)', \n",
    "                           'Rank(10%)', 'Rank(20%)', \n",
    "                           'Sign(10%)', 'Sign(20%)', \n",
    "                           'SignedRank(10%)', 'SignedRank(20%)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3e0587-058a-453f-bb8d-ecd8cd8c4879",
   "metadata": {},
   "source": [
    "Local vs local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e77ab4ea-9f21-4f69-b9ca-14c10623dc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature_agreement': 0.612, 'rank_agreement': 0.457, 'sign_agreement': 0.593, 'signed_rank_agreement': 0.449}\n"
     ]
    }
   ],
   "source": [
    "for key_pair in list(itertools.combinations(xai_keys_list, 2)):\n",
    "    exp_combined_1 = explanations[fold][key_pair[0]]['top'] | explanations[fold][key_pair[0]]['bottom']\n",
    "    exp_combined_2 = explanations[fold][key_pair[1]]['top'] | explanations[fold][key_pair[1]]['bottom']\n",
    "\n",
    "\n",
    "    # Use regex if necessary\n",
    "    if model_type=='xgb':\n",
    "        for project in exp_combined_1:\n",
    "            for item in exp_combined_1[project]:\n",
    "                item[0] = re.sub(r'[&!@,\\)\\(]', '', item[0])\n",
    "\n",
    "        for project in exp_combined_2:\n",
    "            for item in exp_combined_2[project]:\n",
    "                item[0] = re.sub(r'[&!@,\\)\\(]', '', item[0])\n",
    "\n",
    "    \n",
    "    # Top 10%\n",
    "    disagreement_no_comp_top_10_perc = disagreement_average(exp_combined_1, exp_combined_2, True, top_10_perc_uncompressed, None)\n",
    "    disagreement_max_comp_top_10_perc = disagreement_average(exp_combined_1, exp_combined_2, True, top_10_perc_compressed, None, 'max', processed)\n",
    "    disagreement_act_comp_top_10_perc = disagreement_average(exp_combined_1, exp_combined_2, True, top_10_perc_compressed, None, 'activated', processed)\n",
    "    disagreement_maxnonact_comp_top_10_perc = disagreement_average(exp_combined_1, exp_combined_2, True, top_10_perc_compressed, None, 'maxnonactivated', processed)\n",
    "\n",
    "    # Top 20%\n",
    "    disagreement_no_comp_top_20_perc = disagreement_average(exp_combined_1, exp_combined_2, True, top_20_perc_uncompressed, None)\n",
    "    disagreement_max_comp_top_20_perc = disagreement_average(exp_combined_1, exp_combined_2, True, top_20_perc_compressed, None, 'max', processed)\n",
    "    disagreement_act_comp_top_20_perc = disagreement_average(exp_combined_1, exp_combined_2, True, top_20_perc_compressed, None, 'activated', processed)\n",
    "    disagreement_maxnonact_comp_top_20_perc = disagreement_average(exp_combined_1, exp_combined_2, True, top_20_perc_compressed, None, 'maxnonactivated', processed)\n",
    "\n",
    "    # Add to dataframe\n",
    "    df.loc[len(df)] = {'Explanations' : f'{key_pair[0]}_vs_{key_pair[1]}', \n",
    "                    'Compactor' : 'No compactor', \n",
    "                    'Model' : model_type_save, \n",
    "                    'Feature(10%)': disagreement_no_comp_top_10_perc['feature_agreement'], \n",
    "                    'Feature(20%)': disagreement_no_comp_top_20_perc['feature_agreement'], \n",
    "                    'Rank(10%)': disagreement_no_comp_top_10_perc['rank_agreement'], \n",
    "                    'Rank(20%)': disagreement_no_comp_top_20_perc['rank_agreement'], \n",
    "                    'Sign(10%)': disagreement_no_comp_top_10_perc['sign_agreement'], \n",
    "                    'Sign(20%)': disagreement_no_comp_top_20_perc['sign_agreement'], \n",
    "                    'SignedRank(10%)': disagreement_no_comp_top_10_perc['signed_rank_agreement'], \n",
    "                    'SignedRank(20%)': disagreement_no_comp_top_20_perc['signed_rank_agreement']}\n",
    "    \n",
    "    df.loc[len(df)] = {'Explanations' : f'{key_pair[0]}_vs_{key_pair[1]}', \n",
    "                    'Compactor' : 'Max compactor', \n",
    "                    'Model' : model_type_save, \n",
    "                    'Feature(10%)': disagreement_max_comp_top_10_perc['feature_agreement'], \n",
    "                    'Feature(20%)': disagreement_max_comp_top_20_perc['feature_agreement'], \n",
    "                    'Rank(10%)': disagreement_max_comp_top_10_perc['rank_agreement'], \n",
    "                    'Rank(20%)': disagreement_max_comp_top_20_perc['rank_agreement'], \n",
    "                    'Sign(10%)': disagreement_max_comp_top_10_perc['sign_agreement'], \n",
    "                    'Sign(20%)': disagreement_max_comp_top_20_perc['sign_agreement'], \n",
    "                    'SignedRank(10%)': disagreement_max_comp_top_10_perc['signed_rank_agreement'], \n",
    "                    'SignedRank(20%)': disagreement_max_comp_top_20_perc['signed_rank_agreement']}\n",
    "    \n",
    "    df.loc[len(df)] = {'Explanations' : f'{key_pair[0]}_vs_{key_pair[1]}', \n",
    "                    'Compactor' : 'Activated compactor', \n",
    "                    'Model' : model_type_save, \n",
    "                    'Feature(10%)': disagreement_act_comp_top_10_perc['feature_agreement'], \n",
    "                    'Feature(20%)': disagreement_act_comp_top_20_perc['feature_agreement'], \n",
    "                    'Rank(10%)': disagreement_act_comp_top_10_perc['rank_agreement'], \n",
    "                    'Rank(20%)': disagreement_act_comp_top_20_perc['rank_agreement'], \n",
    "                    'Sign(10%)': disagreement_act_comp_top_10_perc['sign_agreement'], \n",
    "                    'Sign(20%)': disagreement_act_comp_top_20_perc['sign_agreement'], \n",
    "                    'SignedRank(10%)': disagreement_act_comp_top_10_perc['signed_rank_agreement'], \n",
    "                    'SignedRank(20%)': disagreement_act_comp_top_20_perc['signed_rank_agreement']}\n",
    "\n",
    "    df.loc[len(df)] = {'Explanations' : f'{key_pair[0]}_vs_{key_pair[1]}', \n",
    "                    'Compactor' : 'Non-activated max compactor', \n",
    "                    'Model' : model_type_save, \n",
    "                    'Feature(10%)': disagreement_maxnonact_comp_top_10_perc['feature_agreement'], \n",
    "                    'Feature(20%)': disagreement_maxnonact_comp_top_20_perc['feature_agreement'], \n",
    "                    'Rank(10%)': disagreement_maxnonact_comp_top_10_perc['rank_agreement'], \n",
    "                    'Rank(20%)': disagreement_maxnonact_comp_top_20_perc['rank_agreement'], \n",
    "                    'Sign(10%)': disagreement_maxnonact_comp_top_10_perc['sign_agreement'], \n",
    "                    'Sign(20%)': disagreement_maxnonact_comp_top_20_perc['sign_agreement'], \n",
    "                    'SignedRank(10%)': disagreement_maxnonact_comp_top_10_perc['signed_rank_agreement'], \n",
    "                    'SignedRank(20%)': disagreement_maxnonact_comp_top_20_perc['signed_rank_agreement']}\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10996627-508b-45ea-84eb-8909cbc44316",
   "metadata": {},
   "source": [
    "Global vs local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8178c2f9-b79c-4643-a8e5-c42f49041a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature_agreement': 0.41, 'rank_agreement': 0.284, 'sign_agreement': 0.192, 'signed_rank_agreement': 0.151}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m exp_combined[project]:\n\u001b[1;32m      8\u001b[0m             item[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[&!@,\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m(]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, item[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 11\u001b[0m disagreement_act_comp_top_10_perc \u001b[38;5;241m=\u001b[39m \u001b[43mdisagreement_average\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_combined\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_explanation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_10_perc_compressed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mactivated\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(disagreement_act_comp_top_10_perc)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m# Top 10%\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03mdisagreement_no_comp_top_10_perc = disagreement_average(exp_combined, global_explanation.values, False, top_10_perc_uncompressed, None)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     75\u001b[0m \n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[62], line 36\u001b[0m, in \u001b[0;36mdisagreement_average\u001b[0;34m(explanations1, explanations2, both_local, k, features_F, method, raw_data, debug)\u001b[0m\n\u001b[1;32m     34\u001b[0m activated_features \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m categorical_cols:\n\u001b[0;32m---> 36\u001b[0m     sub_feature \u001b[38;5;241m=\u001b[39m raw_data[\u001b[43mraw_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mProject ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mproject_id\u001b[49m ][feature]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_type\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxgb\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m model_type\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlgbm\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     39\u001b[0m         sub_feature \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[&!@,\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m(]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, sub_feature)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/series.py:5804\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   5801\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   5802\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 5804\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5806\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/ops/array_ops.py:346\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 346\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/ops/array_ops.py:131\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m    129\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mvec_compare(x\u001b[38;5;241m.\u001b[39mravel(), y\u001b[38;5;241m.\u001b[39mravel(), op)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 131\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mlibops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalar_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for local_key in xai_keys_list:\n",
    "    exp_combined = explanations[fold][local_key]['top'] | explanations[fold][local_key]['bottom']\n",
    "\n",
    "    # Use regex if necessary\n",
    "    if model_type=='xgb':\n",
    "        for project in exp_combined:\n",
    "            for item in exp_combined[project]:\n",
    "                item[0] = re.sub(r'[&!@,\\)\\(]', '', item[0])\n",
    "\n",
    "\n",
    "    # Top 10%\n",
    "    disagreement_no_comp_top_10_perc = disagreement_average(exp_combined, global_explanation.values, False, top_10_perc_uncompressed, None)\n",
    "    disagreement_max_comp_top_10_perc = disagreement_average(exp_combined, global_explanation.values, False, top_10_perc_compressed, None, 'max', processed)\n",
    "    disagreement_act_comp_top_10_perc = disagreement_average(exp_combined, global_explanation.values, False, top_10_perc_compressed, None, 'activated', processed)\n",
    "    disagreement_maxnonact_comp_top_10_perc = disagreement_average(exp_combined, global_explanation.values, False, top_10_perc_compressed, None, 'maxnonactivated', processed)\n",
    "\n",
    "    # Top 20%\n",
    "    disagreement_no_comp_top_20_perc = disagreement_average(exp_combined, global_explanation.values, False, top_20_perc_uncompressed, None)\n",
    "    disagreement_max_comp_top_20_perc = disagreement_average(exp_combined, global_explanation.values, False, top_20_perc_compressed, None, 'max', processed)\n",
    "    disagreement_act_comp_top_20_perc = disagreement_average(exp_combined, global_explanation.values, False, top_20_perc_compressed, None, 'activated', processed)\n",
    "    disagreement_maxnonact_comp_top_20_perc = disagreement_average(exp_combined, global_explanation.values, False, top_20_perc_compressed, None, 'maxnonactivated', processed)\n",
    "\n",
    "    # Add to dataframe\n",
    "    df.loc[len(df)] = {'Explanations' : f'Global_vs_{local_key}', \n",
    "                    'Compactor' : 'No compactor', \n",
    "                    'Model' : model_type_save, \n",
    "                    'Feature(10%)': disagreement_no_comp_top_10_perc['feature_agreement'], \n",
    "                    'Feature(20%)': disagreement_no_comp_top_20_perc['feature_agreement'], \n",
    "                    'Rank(10%)': disagreement_no_comp_top_10_perc['rank_agreement'], \n",
    "                    'Rank(20%)': disagreement_no_comp_top_20_perc['rank_agreement'], \n",
    "                    'Sign(10%)': disagreement_no_comp_top_10_perc['sign_agreement'], \n",
    "                    'Sign(20%)': disagreement_no_comp_top_20_perc['sign_agreement'], \n",
    "                    'SignedRank(10%)': disagreement_no_comp_top_10_perc['signed_rank_agreement'], \n",
    "                    'SignedRank(20%)': disagreement_no_comp_top_20_perc['signed_rank_agreement']}\n",
    "    \n",
    "    df.loc[len(df)] = {'Explanations' : f'Global_vs_{local_key}', \n",
    "                    'Compactor' : 'Max compactor', \n",
    "                    'Model' : model_type_save, \n",
    "                    'Feature(10%)': disagreement_max_comp_top_10_perc['feature_agreement'], \n",
    "                    'Feature(20%)': disagreement_max_comp_top_20_perc['feature_agreement'], \n",
    "                    'Rank(10%)': disagreement_max_comp_top_10_perc['rank_agreement'], \n",
    "                    'Rank(20%)': disagreement_max_comp_top_20_perc['rank_agreement'], \n",
    "                    'Sign(10%)': disagreement_max_comp_top_10_perc['sign_agreement'], \n",
    "                    'Sign(20%)': disagreement_max_comp_top_20_perc['sign_agreement'], \n",
    "                    'SignedRank(10%)': disagreement_max_comp_top_10_perc['signed_rank_agreement'], \n",
    "                    'SignedRank(20%)': disagreement_max_comp_top_20_perc['signed_rank_agreement']}\n",
    "\n",
    "    df.loc[len(df)] = {'Explanations' : f'Global_vs_{local_key}', \n",
    "                    'Compactor' : 'Activated compactor', \n",
    "                    'Model' : model_type_save, \n",
    "                    'Feature(10%)': disagreement_act_comp_top_10_perc['feature_agreement'], \n",
    "                    'Feature(20%)': disagreement_act_comp_top_20_perc['feature_agreement'], \n",
    "                    'Rank(10%)': disagreement_act_comp_top_10_perc['rank_agreement'], \n",
    "                    'Rank(20%)': disagreement_act_comp_top_20_perc['rank_agreement'], \n",
    "                    'Sign(10%)': disagreement_act_comp_top_10_perc['sign_agreement'], \n",
    "                    'Sign(20%)': disagreement_act_comp_top_20_perc['sign_agreement'], \n",
    "                    'SignedRank(10%)': disagreement_act_comp_top_10_perc['signed_rank_agreement'], \n",
    "                    'SignedRank(20%)': disagreement_act_comp_top_20_perc['signed_rank_agreement']}\n",
    "\n",
    "    \n",
    "    df.loc[len(df)] = {'Explanations' : f'Global_vs_{local_key}', \n",
    "                    'Compactor' : 'Non-activated max compactor', \n",
    "                    'Model' : model_type_save, \n",
    "                    'Feature(10%)': disagreement_maxnonact_comp_top_10_perc['feature_agreement'], \n",
    "                    'Feature(20%)': disagreement_maxnonact_comp_top_20_perc['feature_agreement'], \n",
    "                    'Rank(10%)': disagreement_maxnonact_comp_top_10_perc['rank_agreement'], \n",
    "                    'Rank(20%)': disagreement_maxnonact_comp_top_20_perc['rank_agreement'], \n",
    "                    'Sign(10%)': disagreement_maxnonact_comp_top_10_perc['sign_agreement'], \n",
    "                    'Sign(20%)': disagreement_maxnonact_comp_top_20_perc['sign_agreement'], \n",
    "                    'SignedRank(10%)': disagreement_maxnonact_comp_top_10_perc['signed_rank_agreement'], \n",
    "                    'SignedRank(20%)': disagreement_maxnonact_comp_top_20_perc['signed_rank_agreement']}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2990832f-a98d-4273-96d8-dcb9edb3baaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save df as csv\n",
    "df.to_csv(f'{save_path}agreement_all_exp_{model_type}_{fold}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
