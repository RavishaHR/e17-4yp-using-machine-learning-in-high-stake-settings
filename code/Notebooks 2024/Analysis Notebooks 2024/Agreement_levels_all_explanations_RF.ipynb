{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a061ffc0-21fb-4f10-857b-ca293887cc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import json\n",
    "from typing import Union\n",
    "import numpy as np\n",
    "import itertools\n",
    "from disagreement import Disagreement\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15b2d91f-2f2a-4f20-9b17-ed2b46eb80ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from compactor.MaxNonActivatedCompactor import MaxNonActivatedCompactor\n",
    "from compactor.ActivatedCompactor import ActivatedCompactor\n",
    "from compactor.MaxCompactor import MaxCompactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61bb1c46-3c3a-4a5a-9237-4126e87445c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest_t_1000_md_10_fold_1_2016-01-07.sav\n",
      "random_forest_t_1000_md_10_fold_2_2015-09-09.sav\n",
      "random_forest_t_1000_md_10_fold_3_2015-05-12.sav\n",
      "random_forest_t_1000_md_10_fold_4_2015-01-12.sav\n",
      "random_forest_t_1000_md_10_fold_5_2014-09-14.sav\n",
      "random_forest_t_1000_md_10_fold_6_2014-05-17.sav\n",
      "test_prediction_fold_1_2016-01-07.csv\n",
      "test_prediction_fold_2_2015-09-09.csv\n",
      "test_prediction_fold_3_2015-05-12.csv\n",
      "test_prediction_fold_4_2015-01-12.csv\n",
      "test_prediction_fold_5_2014-09-14.csv\n",
      "test_prediction_fold_6_2014-05-17.csv\n"
     ]
    }
   ],
   "source": [
    "!ls /storage/scratch/e17-fyp-xai/projects/e17-4yp-using-machine-learning-in-high-stake-settings/code/new/model_outputs/artifacts/random_forest_t_1000_md_10/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67dc1146-fd99-4f9b-8624-12173aff92c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/storage/scratch/e17-fyp-xai/projects/e17-4yp-using-machine-learning-in-high-stake-settings/code/new/model_outputs/\"\n",
    "model_path = \"random_forest_t_1000_md_10/\" # Change\n",
    "model_name = \"random_forest_t_1000_md_10_fold_4_2015-01-12.sav\" # Change\n",
    "xai_root = root + \"xai/2024/\"\n",
    "art_root = root + \"artifacts/\"\n",
    "analysis_path = root + \"analysis/2024/\"\n",
    "json_file_path = xai_root + model_path + \"all_exp.json\"\n",
    "processed_data_path = \"/storage/scratch/e17-fyp-xai/projects/e17-4yp-using-machine-learning-in-high-stake-settings/code/processed_data/processed_final_data_latest.csv\"\n",
    "\n",
    "fold = 'fold4' # Change\n",
    "model_type = 'rf' # Types: nn, xgb, lgbm, lr, rf # Change\n",
    "\n",
    "model_type_save = 'RF'\n",
    "\n",
    "save_path = analysis_path + model_path + f\"agreement_levels_all_explanations/{fold}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d5b93cb-d963-4ee9-b5e2-3981d575a08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_nocomp = True\n",
    "create_max = True\n",
    "create_act = True\n",
    "create_maxnonact = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cac614b9-6fab-4156-8ae7-7c80cd53c70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change directory and import\n",
    "os.chdir(\"/storage/scratch/e17-fyp-xai/projects/mad_v3/e17-4yp-using-machine-learning-in-high-stake-settings/code/\")\n",
    "import config\n",
    "categorical_cols = config.CATEGORICAL_COLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d482c97d-3688-4fd0-9b9f-873218199d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "# Function to save images\n",
    "def save_image(caption, path):\n",
    "    set_path = f'{path}/{caption}.png'\n",
    "    plt.savefig(set_path)\n",
    "\n",
    "def make_directory(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f0512fe-10ae-415f-8326-e8ce298993f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_directory(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c548d4d6-f3f8-4303-8bd7-79fa58b77e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Project ID', 'Project Posted Date', 'Project Type',\n",
       "       'Project Posted Month', 'Project Subject Category Tree', 'Project Cost',\n",
       "       'Project Subject Subcategory Tree', 'Project Grade Level Category',\n",
       "       'Project Resource Category', 'School Metro Type', 'School State',\n",
       "       'Teacher Project Posted Sequence', 'Label', 'Teacher Success Rate',\n",
       "       'Teacher Success Rate Imputed', 'School City Success Rate',\n",
       "       'School City Success Rate Imputed', 'School Success Rate',\n",
       "       'School Success Rate Imputed', 'School County Success Rate',\n",
       "       'School County Success Rate Imputed', 'Project Count in State',\n",
       "       'Project Need Statement Length', 'School City',\n",
       "       'Project Need Statement', 'Resource Vendor Name', 'Teacher Prefix',\n",
       "       'Project Short Description Length', 'School County',\n",
       "       'Project Count in County', 'Project Title', 'Project Essay',\n",
       "       'Resource Cost Percentage', 'Project Essay Length',\n",
       "       'School Percentage Free Lunch', 'Resource Cost',\n",
       "       'Resource Cost Imputed', 'Project Count in City',\n",
       "       'Project Short Description', 'School Percentage Free Lunch Imputed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read dataframe to get actual label and for the categorical columns\n",
    "processed = pd.read_csv(processed_data_path)\n",
    "processed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72745667-81ad-4828-a500-d75257a1c84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load explanations\n",
    "explanations = json.load(open(json_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adf56391-2b8d-40ca-a70a-926068adf1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lime_fs_auto_sai_True_nums_1000', 'lime_fs_auto_sai_False_nums_5000', 'treeshap_alg_auto_tr_None', 'treeshap_alg_deep_tr_100']\n"
     ]
    }
   ],
   "source": [
    "xai_keys_list = list(explanations[fold].keys())\n",
    "print(xai_keys_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "876f7d7a-029a-43f8-908c-ddb4fd9e64ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 122 3 6\n"
     ]
    }
   ],
   "source": [
    "# Set n features values\n",
    "top_keys = list(explanations[fold][xai_keys_list[0]]['top'].keys())\n",
    "bottom_keys = list(explanations[fold][xai_keys_list[0]]['bottom'].keys())\n",
    "top_10_perc_uncompressed = round(len(explanations[fold][xai_keys_list[0]]['top'][top_keys[0]])* 0.1) \n",
    "top_20_perc_uncompressed = round(len(explanations[fold][xai_keys_list[0]]['top'][top_keys[0]])* 0.2)\n",
    "top_10_perc_compressed = round(31* 0.1) \n",
    "top_20_perc_compressed = round(31* 0.2)\n",
    "print(top_10_perc_uncompressed, top_20_perc_uncompressed, top_10_perc_compressed, top_20_perc_compressed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe6a5431-c87c-4d79-a5bb-d752a22bc1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disagreement_average(explanations1: dict, explanations2: dict, both_local: bool, k: int, features_F: list, method = None, raw_data = None, debug = False) -> dict:\n",
    "    \n",
    "    disagreement_mean = {'feature_agreement': 0.0,\n",
    "                         'rank_agreement': 0.0,\n",
    "                         'sign_agreement': 0.0,\n",
    "                         'signed_rank_agreement': 0.0}\n",
    "\n",
    "    # explanations_1 is always local\n",
    "    # explanations_2 can either be local or global\n",
    "    \n",
    "    for project_id in explanations1.keys():\n",
    "        if debug:\n",
    "            print(f\"******************Project ID: {project_id}************************\")\n",
    "        \n",
    "        disagreement_calc = None\n",
    "\n",
    "       \n",
    "        # Initialize disagreement calculation\n",
    "        if both_local:\n",
    "            disagreement_calc = Disagreement(explanations1[project_id], explanations2[project_id])\n",
    "        else:\n",
    "            disagreement_calc = Disagreement(explanations2, explanations1[project_id])\n",
    "        \n",
    "        if debug:\n",
    "            print(\"Initial Explanation 1 \\n\", disagreement_calc.sorted_explanation1[:k])\n",
    "            print(\"Initial Explanation 2 \\n\", disagreement_calc.sorted_explanation2[:k])\n",
    "            \n",
    "        if method==\"max\":\n",
    "            max_compactor = MaxCompactor(categorical_cols)\n",
    "            disagreement_calc.compact_features(max_compactor)\n",
    "            \n",
    "            \n",
    "        elif method == \"activated\" and raw_data is not None:\n",
    "            activated_features = {}\n",
    "            for feature in categorical_cols:\n",
    "                activated_features[feature] = f\"{feature}_{raw_data[raw_data['Project ID'] == project_id ][feature].values[0]}\"\n",
    "            activated_compactor = ActivatedCompactor(activated_features)\n",
    "            disagreement_calc.compact_features(activated_compactor)\n",
    "            \n",
    "        elif method == \"maxnonactivated\" and raw_data is not None:\n",
    "            activated_features = {}\n",
    "            for feature in categorical_cols:\n",
    "                activated_features[feature] = f\"{feature}_{raw_data[raw_data['Project ID'] == project_id ][feature].values[0]}\"\n",
    "            max_non_activated_compactor = MaxNonActivatedCompactor(activated_features)\n",
    "            disagreement_calc.compact_features(max_non_activated_compactor)\n",
    "            \n",
    "        if debug:\n",
    "            print(\"After Compact Explanation 1 \\n\",disagreement_calc.sorted_explanation1[:k])\n",
    "            print(\"After Compact Explanation 2 \\n\",disagreement_calc.sorted_explanation2[:k])\n",
    "            \n",
    "            \n",
    "        disagreement = disagreement_calc.get_disagreement(k, features_F)\n",
    "        \n",
    "        if debug:\n",
    "            print(\"Disagreement : \", disagreement)\n",
    "        \n",
    "        for key in list(disagreement_mean.keys()):\n",
    "            if disagreement[key] == None:\n",
    "                raise ValueError(f\"The value for key '{key}' in disagreement_mean is None.\")\n",
    "            disagreement_mean[key] += disagreement[key]\n",
    "        \n",
    "        if debug:\n",
    "            print(\"****************************************\")\n",
    "\n",
    "    for key in list(disagreement_mean.keys()):\n",
    "        disagreement_mean[key] = round(disagreement_mean[key] / len(explanations1.keys()),3)\n",
    "    \n",
    "    if debug:\n",
    "        print(\"*********************************************\")\n",
    "        print(disagreement_mean)\n",
    "        print(\"*********************************************\")\n",
    "\n",
    "    \n",
    "    return disagreement_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6780f2e2-349a-4895-9c04-981b86946068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_feat(model_path, model_name, model_type):\n",
    "    # Load the model\n",
    "    model = None\n",
    "    importance = None\n",
    "    feat_names = None\n",
    "    \n",
    "    if model_type == 'nn':\n",
    "        model_file_path = f'{model_path}{model_name}' \n",
    "        model = keras.models.load_model(model_file_path)\n",
    "        # Skip the rest\n",
    "\n",
    "    elif model_type == 'lgbm':\n",
    "        model_file_path = f'{model_path}{model_name}'\n",
    "        model = joblib.load(model_file_path)\n",
    "        # Load the feature importance array\n",
    "        importance = model.feature_importances_\n",
    "        # Get the feature names\n",
    "        feat_names = model.feature_name_\n",
    "\n",
    "    elif model_type == 'lr':\n",
    "        model_file_path = f'{model_path}{model_name}'\n",
    "        model = joblib.load(model_file_path)\n",
    "        # Load the feature importance array\n",
    "        importance = model.coef_[0]\n",
    "        # Get the feature names\n",
    "        feat_names = model.feature_names_in_\n",
    "    \n",
    "    else:\n",
    "        model_file_path = f'{model_path}{model_name}'\n",
    "        model = joblib.load(model_file_path)\n",
    "        # Load the feature importance array\n",
    "        importance = model.feature_importances_\n",
    "        # Get the feature names\n",
    "        feat_names = model.feature_names_in_\n",
    "    \n",
    "    return importance, feat_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32a40580-f0b5-4ccd-8209-cefd30559231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to select the top k features and plot\n",
    "def select_top_features(importance, feat_names):\n",
    "    # Create df and sort\n",
    "    df = pd.DataFrame({\"Feature\": feat_names, \"Importance\": importance})\n",
    "    #df_sorted = df.sort_values(\"Importance\", ascending=False)\n",
    "    df_sorted = df.reindex(df.Importance.abs().sort_values(ascending=False).index)\n",
    "    return df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95143e09-79a6-454a-9843-379d5c8b2c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Project Cost', 0.21832490517874864],\n",
       "       ['Resource Cost', 0.10584395574442541],\n",
       "       ['School Success Rate', 0.06696661597145076],\n",
       "       ...,\n",
       "       ['Project Subject Subcategory Tree_Special Needs, Warmth, Care & Hunger',\n",
       "        0.0],\n",
       "       ['Project Subject Subcategory Tree_Team Sports, Visual Arts', 0.0],\n",
       "       ['Project Subject Subcategory Tree_Gym & Fitness, Warmth, Care & Hunger',\n",
       "        0.0]], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_importance, feat_names = load_model_and_feat(art_root+model_path, model_name, model_type)\n",
    "#print(global_importance, feat_names)\n",
    "global_explanation = select_top_features(global_importance, feat_names)\n",
    "global_explanation.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9f1b715-7fd1-415c-8657-7143fe94aeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty df - define the column names\n",
    "df = pd.DataFrame(columns=['Explanations', 'Compactor', 'Model', \n",
    "                           'Feature(10%)', 'Feature(20%)', \n",
    "                           'Rank(10%)', 'Rank(20%)', \n",
    "                           'Sign(10%)', 'Sign(20%)', \n",
    "                           'SignedRank(10%)', 'SignedRank(20%)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3e0587-058a-453f-bb8d-ecd8cd8c4879",
   "metadata": {},
   "source": [
    "Local vs local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77ab4ea-9f21-4f69-b9ca-14c10623dc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key_pair in list(itertools.combinations(xai_keys_list, 2)):\n",
    "    exp_combined_1 = explanations[fold][key_pair[0]]['top'] | explanations[fold][key_pair[0]]['bottom']\n",
    "    exp_combined_2 = explanations[fold][key_pair[1]]['top'] | explanations[fold][key_pair[1]]['bottom']\n",
    "    \n",
    "    # Top 10%\n",
    "    disagreement_no_comp_top_10_perc = disagreement_average(exp_combined_1, exp_combined_2, True, top_10_perc_uncompressed, None)\n",
    "    disagreement_max_comp_top_10_perc = disagreement_average(exp_combined_1, exp_combined_2, True, top_10_perc_compressed, None, 'max', processed)\n",
    "    disagreement_act_comp_top_10_perc = disagreement_average(exp_combined_1, exp_combined_2, True, top_10_perc_compressed, None, 'activated', processed)\n",
    "    disagreement_maxnonact_comp_top_10_perc = disagreement_average(exp_combined_1, exp_combined_2, True, top_10_perc_compressed, None, 'maxnonactivated', processed)\n",
    "\n",
    "    # Top 20%\n",
    "    disagreement_no_comp_top_20_perc = disagreement_average(exp_combined_1, exp_combined_2, True, top_20_perc_uncompressed, None)\n",
    "    disagreement_max_comp_top_20_perc = disagreement_average(exp_combined_1, exp_combined_2, True, top_20_perc_compressed, None, 'max', processed)\n",
    "    disagreement_act_comp_top_20_perc = disagreement_average(exp_combined_1, exp_combined_2, True, top_20_perc_compressed, None, 'activated', processed)\n",
    "    disagreement_maxnonact_comp_top_20_perc = disagreement_average(exp_combined_1, exp_combined_2, True, top_20_perc_compressed, None, 'maxnonactivated', processed)\n",
    "\n",
    "    # Add to dataframe\n",
    "    df.loc[len(df)] = {'Explanations' : f'{key_pair[0]}_vs_{key_pair[1]}', \n",
    "                    'Compactor' : 'No compactor', \n",
    "                    'Model' : model_type_save, \n",
    "                    'Feature(10%)': disagreement_no_comp_top_10_perc['feature_agreement'], \n",
    "                    'Feature(20%)': disagreement_no_comp_top_20_perc['feature_agreement'], \n",
    "                    'Rank(10%)': disagreement_no_comp_top_10_perc['rank_agreement'], \n",
    "                    'Rank(20%)': disagreement_no_comp_top_20_perc['rank_agreement'], \n",
    "                    'Sign(10%)': disagreement_no_comp_top_10_perc['sign_agreement'], \n",
    "                    'Sign(20%)': disagreement_no_comp_top_20_perc['sign_agreement'], \n",
    "                    'SignedRank(10%)': disagreement_no_comp_top_10_perc['signed_rank_agreement'], \n",
    "                    'SignedRank(20%)': disagreement_no_comp_top_20_perc['signed_rank_agreement']}\n",
    "    \n",
    "    df.loc[len(df)] = {'Explanations' : f'{key_pair[0]}_vs_{key_pair[1]}', \n",
    "                    'Compactor' : 'Max compactor', \n",
    "                    'Model' : model_type_save, \n",
    "                    'Feature(10%)': disagreement_max_comp_top_10_perc['feature_agreement'], \n",
    "                    'Feature(20%)': disagreement_max_comp_top_20_perc['feature_agreement'], \n",
    "                    'Rank(10%)': disagreement_max_comp_top_10_perc['rank_agreement'], \n",
    "                    'Rank(20%)': disagreement_max_comp_top_20_perc['rank_agreement'], \n",
    "                    'Sign(10%)': disagreement_max_comp_top_10_perc['sign_agreement'], \n",
    "                    'Sign(20%)': disagreement_max_comp_top_20_perc['sign_agreement'], \n",
    "                    'SignedRank(10%)': disagreement_max_comp_top_10_perc['signed_rank_agreement'], \n",
    "                    'SignedRank(20%)': disagreement_max_comp_top_20_perc['signed_rank_agreement']}\n",
    "    \n",
    "    df.loc[len(df)] = {'Explanations' : f'{key_pair[0]}_vs_{key_pair[1]}', \n",
    "                    'Compactor' : 'Activated compactor', \n",
    "                    'Model' : model_type_save, \n",
    "                    'Feature(10%)': disagreement_act_comp_top_10_perc['feature_agreement'], \n",
    "                    'Feature(20%)': disagreement_act_comp_top_20_perc['feature_agreement'], \n",
    "                    'Rank(10%)': disagreement_act_comp_top_10_perc['rank_agreement'], \n",
    "                    'Rank(20%)': disagreement_act_comp_top_20_perc['rank_agreement'], \n",
    "                    'Sign(10%)': disagreement_act_comp_top_10_perc['sign_agreement'], \n",
    "                    'Sign(20%)': disagreement_act_comp_top_20_perc['sign_agreement'], \n",
    "                    'SignedRank(10%)': disagreement_act_comp_top_10_perc['signed_rank_agreement'], \n",
    "                    'SignedRank(20%)': disagreement_act_comp_top_20_perc['signed_rank_agreement']}\n",
    "\n",
    "    df.loc[len(df)] = {'Explanations' : f'{key_pair[0]}_vs_{key_pair[1]}', \n",
    "                    'Compactor' : 'Non-activated max compactor', \n",
    "                    'Model' : model_type_save, \n",
    "                    'Feature(10%)': disagreement_maxnonact_comp_top_10_perc['feature_agreement'], \n",
    "                    'Feature(20%)': disagreement_maxnonact_comp_top_20_perc['feature_agreement'], \n",
    "                    'Rank(10%)': disagreement_maxnonact_comp_top_10_perc['rank_agreement'], \n",
    "                    'Rank(20%)': disagreement_maxnonact_comp_top_20_perc['rank_agreement'], \n",
    "                    'Sign(10%)': disagreement_maxnonact_comp_top_10_perc['sign_agreement'], \n",
    "                    'Sign(20%)': disagreement_maxnonact_comp_top_20_perc['sign_agreement'], \n",
    "                    'SignedRank(10%)': disagreement_maxnonact_comp_top_10_perc['signed_rank_agreement'], \n",
    "                    'SignedRank(20%)': disagreement_maxnonact_comp_top_20_perc['signed_rank_agreement']}\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10996627-508b-45ea-84eb-8909cbc44316",
   "metadata": {},
   "source": [
    "Global vs local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8178c2f9-b79c-4643-a8e5-c42f49041a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for local_key in xai_keys_list:\n",
    "    exp_combined = explanations[fold][local_key]['top'] | explanations[fold][local_key]['bottom']\n",
    "\n",
    "    # Top 10%\n",
    "    disagreement_no_comp_top_10_perc = disagreement_average(exp_combined, global_explanation.values, False, top_10_perc_uncompressed, None)\n",
    "    disagreement_max_comp_top_10_perc = disagreement_average(exp_combined, global_explanation.values, False, top_10_perc_compressed, None, 'max', processed)\n",
    "    disagreement_act_comp_top_10_perc = disagreement_average(exp_combined, global_explanation.values, False, top_10_perc_compressed, None, 'activated', processed)\n",
    "    disagreement_maxnonact_comp_top_10_perc = disagreement_average(exp_combined, global_explanation.values, False, top_10_perc_compressed, None, 'maxnonactivated', processed)\n",
    "\n",
    "    # Top 20%\n",
    "    disagreement_no_comp_top_20_perc = disagreement_average(exp_combined, global_explanation.values, False, top_20_perc_uncompressed, None)\n",
    "    disagreement_max_comp_top_20_perc = disagreement_average(exp_combined, global_explanation.values, False, top_20_perc_compressed, None, 'max', processed)\n",
    "    disagreement_act_comp_top_20_perc = disagreement_average(exp_combined, global_explanation.values, False, top_20_perc_compressed, None, 'activated', processed)\n",
    "    disagreement_maxnonact_comp_top_20_perc = disagreement_average(exp_combined, global_explanation.values, False, top_20_perc_compressed, None, 'maxnonactivated', processed)\n",
    "\n",
    "    # Add to dataframe\n",
    "    df.loc[len(df)] = {'Explanations' : f'Global_vs_{local_key}', \n",
    "                    'Compactor' : 'No compactor', \n",
    "                    'Model' : model_type_save, \n",
    "                    'Feature(10%)': disagreement_no_comp_top_10_perc['feature_agreement'], \n",
    "                    'Feature(20%)': disagreement_no_comp_top_20_perc['feature_agreement'], \n",
    "                    'Rank(10%)': disagreement_no_comp_top_10_perc['rank_agreement'], \n",
    "                    'Rank(20%)': disagreement_no_comp_top_20_perc['rank_agreement'], \n",
    "                    'Sign(10%)': disagreement_no_comp_top_10_perc['sign_agreement'], \n",
    "                    'Sign(20%)': disagreement_no_comp_top_20_perc['sign_agreement'], \n",
    "                    'SignedRank(10%)': disagreement_no_comp_top_10_perc['signed_rank_agreement'], \n",
    "                    'SignedRank(20%)': disagreement_no_comp_top_20_perc['signed_rank_agreement']}\n",
    "    \n",
    "    df.loc[len(df)] = {'Explanations' : f'Global_vs_{local_key}', \n",
    "                    'Compactor' : 'Max compactor', \n",
    "                    'Model' : model_type_save, \n",
    "                    'Feature(10%)': disagreement_max_comp_top_10_perc['feature_agreement'], \n",
    "                    'Feature(20%)': disagreement_max_comp_top_20_perc['feature_agreement'], \n",
    "                    'Rank(10%)': disagreement_max_comp_top_10_perc['rank_agreement'], \n",
    "                    'Rank(20%)': disagreement_max_comp_top_20_perc['rank_agreement'], \n",
    "                    'Sign(10%)': disagreement_max_comp_top_10_perc['sign_agreement'], \n",
    "                    'Sign(20%)': disagreement_max_comp_top_20_perc['sign_agreement'], \n",
    "                    'SignedRank(10%)': disagreement_max_comp_top_10_perc['signed_rank_agreement'], \n",
    "                    'SignedRank(20%)': disagreement_max_comp_top_20_perc['signed_rank_agreement']}\n",
    "\n",
    "    df.loc[len(df)] = {'Explanations' : f'Global_vs_{local_key}', \n",
    "                    'Compactor' : 'Activated compactor', \n",
    "                    'Model' : model_type_save, \n",
    "                    'Feature(10%)': disagreement_act_comp_top_10_perc['feature_agreement'], \n",
    "                    'Feature(20%)': disagreement_act_comp_top_20_perc['feature_agreement'], \n",
    "                    'Rank(10%)': disagreement_act_comp_top_10_perc['rank_agreement'], \n",
    "                    'Rank(20%)': disagreement_act_comp_top_20_perc['rank_agreement'], \n",
    "                    'Sign(10%)': disagreement_act_comp_top_10_perc['sign_agreement'], \n",
    "                    'Sign(20%)': disagreement_act_comp_top_20_perc['sign_agreement'], \n",
    "                    'SignedRank(10%)': disagreement_act_comp_top_10_perc['signed_rank_agreement'], \n",
    "                    'SignedRank(20%)': disagreement_act_comp_top_20_perc['signed_rank_agreement']}\n",
    "\n",
    "    \n",
    "    df.loc[len(df)] = {'Explanations' : f'Global_vs_{local_key}', \n",
    "                    'Compactor' : 'Non-activated max compactor', \n",
    "                    'Model' : model_type_save, \n",
    "                    'Feature(10%)': disagreement_maxnonact_comp_top_10_perc['feature_agreement'], \n",
    "                    'Feature(20%)': disagreement_maxnonact_comp_top_20_perc['feature_agreement'], \n",
    "                    'Rank(10%)': disagreement_maxnonact_comp_top_10_perc['rank_agreement'], \n",
    "                    'Rank(20%)': disagreement_maxnonact_comp_top_20_perc['rank_agreement'], \n",
    "                    'Sign(10%)': disagreement_maxnonact_comp_top_10_perc['sign_agreement'], \n",
    "                    'Sign(20%)': disagreement_maxnonact_comp_top_20_perc['sign_agreement'], \n",
    "                    'SignedRank(10%)': disagreement_maxnonact_comp_top_10_perc['signed_rank_agreement'], \n",
    "                    'SignedRank(20%)': disagreement_maxnonact_comp_top_20_perc['signed_rank_agreement']}\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2990832f-a98d-4273-96d8-dcb9edb3baaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save df as csv\n",
    "df.to_csv(f'{save_path}agreement_all_exp_{model_type}_{fold}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
