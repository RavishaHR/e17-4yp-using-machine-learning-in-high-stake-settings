{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a061ffc0-21fb-4f10-857b-ca293887cc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import json\n",
    "from typing import Union\n",
    "import numpy as np\n",
    "import itertools\n",
    "from disagreement import Disagreement\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15b2d91f-2f2a-4f20-9b17-ed2b46eb80ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from compactor.MaxNonActivatedCompactor import MaxNonActivatedCompactor\n",
    "from compactor.ActivatedCompactor import ActivatedCompactor\n",
    "from compactor.MaxCompactor import MaxCompactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4484a58f-9aad-4d81-8407-a47cd50a07b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn_lr_0.005_loss_binary_crossentropy_activation_relu_epochs_40_fold_1_2016-01-07.h5\n",
      "nn_lr_0.005_loss_binary_crossentropy_activation_relu_epochs_40_fold_2_2015-09-09.h5\n",
      "nn_lr_0.005_loss_binary_crossentropy_activation_relu_epochs_40_fold_3_2015-05-12.h5\n",
      "nn_lr_0.005_loss_binary_crossentropy_activation_relu_epochs_40_fold_4_2015-01-12.h5\n",
      "nn_lr_0.005_loss_binary_crossentropy_activation_relu_epochs_40_fold_5_2014-09-14.h5\n",
      "nn_lr_0.005_loss_binary_crossentropy_activation_relu_epochs_40_fold_6_2014-05-17.h5\n",
      "test_prediction_fold_1_2016-01-07.csv\n",
      "test_prediction_fold_2_2015-09-09.csv\n",
      "test_prediction_fold_3_2015-05-12.csv\n",
      "test_prediction_fold_4_2015-01-12.csv\n",
      "test_prediction_fold_5_2014-09-14.csv\n",
      "test_prediction_fold_6_2014-05-17.csv\n"
     ]
    }
   ],
   "source": [
    "!ls /storage/scratch/e17-fyp-xai/projects/e17-4yp-using-machine-learning-in-high-stake-settings/code/new/model_outputs/artifacts/nn_lr_0.005_loss_binary_crossentropy_activation_relu_epochs_40/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67dc1146-fd99-4f9b-8624-12173aff92c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/storage/scratch/e17-fyp-xai/projects/e17-4yp-using-machine-learning-in-high-stake-settings/code/new/model_outputs/\"\n",
    "model_path = \"nn_lr_0.005_loss_binary_crossentropy_activation_relu_epochs_40/\" # Change\n",
    "model_name = \"nn_lr_0.005_loss_binary_crossentropy_activation_relu_epochs_40_fold_3_2015-05-12.h5\" # Change\n",
    "xai_root = root + \"xai/2024/\"\n",
    "art_root = root + \"artifacts/\"\n",
    "analysis_path = root + \"analysis/2024/\"\n",
    "json_file_path = xai_root + model_path + \"all_exp.json\"\n",
    "processed_data_path = \"/storage/scratch/e17-fyp-xai/projects/e17-4yp-using-machine-learning-in-high-stake-settings/code/processed_data/processed_final_data_latest.csv\"\n",
    "\n",
    "fold = 'fold3' # Change\n",
    "model_type = 'nn' # Types: nn, xgb, lgbm, lr, rf # Change\n",
    "\n",
    "model_type_save = 'NN'\n",
    "\n",
    "save_path = analysis_path + model_path + f\"agreement_levels_all_explanations/{fold}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d5b93cb-d963-4ee9-b5e2-3981d575a08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_nocomp = True\n",
    "create_max = True\n",
    "create_act = True\n",
    "create_maxnonact = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cac614b9-6fab-4156-8ae7-7c80cd53c70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change directory and import\n",
    "os.chdir(\"/storage/scratch/e17-fyp-xai/projects/mad_v3/e17-4yp-using-machine-learning-in-high-stake-settings/code/\")\n",
    "import config\n",
    "categorical_cols = config.CATEGORICAL_COLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d482c97d-3688-4fd0-9b9f-873218199d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "# Function to save images\n",
    "def save_image(caption, path):\n",
    "    set_path = f'{path}/{caption}.png'\n",
    "    plt.savefig(set_path)\n",
    "\n",
    "def make_directory(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f0512fe-10ae-415f-8326-e8ce298993f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_directory(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c548d4d6-f3f8-4303-8bd7-79fa58b77e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Project ID', 'Project Posted Date', 'Project Type',\n",
       "       'Project Posted Month', 'Project Subject Category Tree', 'Project Cost',\n",
       "       'Project Subject Subcategory Tree', 'Project Grade Level Category',\n",
       "       'Project Resource Category', 'School Metro Type', 'School State',\n",
       "       'Teacher Project Posted Sequence', 'Label', 'Teacher Success Rate',\n",
       "       'Teacher Success Rate Imputed', 'School City Success Rate',\n",
       "       'School City Success Rate Imputed', 'School Success Rate',\n",
       "       'School Success Rate Imputed', 'School County Success Rate',\n",
       "       'School County Success Rate Imputed', 'Project Count in State',\n",
       "       'Project Need Statement Length', 'School City',\n",
       "       'Project Need Statement', 'Resource Vendor Name', 'Teacher Prefix',\n",
       "       'Project Short Description Length', 'School County',\n",
       "       'Project Count in County', 'Project Title', 'Project Essay',\n",
       "       'Resource Cost Percentage', 'Project Essay Length',\n",
       "       'School Percentage Free Lunch', 'Resource Cost',\n",
       "       'Resource Cost Imputed', 'Project Count in City',\n",
       "       'Project Short Description', 'School Percentage Free Lunch Imputed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read dataframe to get actual label and for the categorical columns\n",
    "processed = pd.read_csv(processed_data_path)\n",
    "processed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72745667-81ad-4828-a500-d75257a1c84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load explanations\n",
    "explanations = json.load(open(json_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adf56391-2b8d-40ca-a70a-926068adf1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lime_fs_auto_sai_True_nums_1000', 'lime_fs_auto_sai_False_nums_5000', 'deepshap_lpf_None']\n"
     ]
    }
   ],
   "source": [
    "xai_keys_list = list(explanations[fold].keys())\n",
    "print(xai_keys_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "876f7d7a-029a-43f8-908c-ddb4fd9e64ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 122 3 6\n"
     ]
    }
   ],
   "source": [
    "# Set n features values\n",
    "top_keys = list(explanations[fold][xai_keys_list[0]]['top'].keys())\n",
    "bottom_keys = list(explanations[fold][xai_keys_list[0]]['bottom'].keys())\n",
    "top_10_perc_uncompressed = round(len(explanations[fold][xai_keys_list[0]]['top'][top_keys[0]])* 0.1) \n",
    "top_20_perc_uncompressed = round(len(explanations[fold][xai_keys_list[0]]['top'][top_keys[0]])* 0.2)\n",
    "top_10_perc_compressed = round(31* 0.1) \n",
    "top_20_perc_compressed = round(31* 0.2)\n",
    "print(top_10_perc_uncompressed, top_20_perc_uncompressed, top_10_perc_compressed, top_20_perc_compressed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe6a5431-c87c-4d79-a5bb-d752a22bc1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disagreement_average(explanations1: dict, explanations2: dict, both_local: bool, k: int, features_F: list, method = None, raw_data = None, debug = False) -> dict:\n",
    "    \n",
    "    disagreement_mean = {'feature_agreement': 0.0,\n",
    "                         'rank_agreement': 0.0,\n",
    "                         'sign_agreement': 0.0,\n",
    "                         'signed_rank_agreement': 0.0}\n",
    "\n",
    "    # explanations_1 is always local\n",
    "    # explanations_2 can either be local or global\n",
    "    \n",
    "    for project_id in explanations1.keys():\n",
    "        if debug:\n",
    "            print(f\"******************Project ID: {project_id}************************\")\n",
    "        \n",
    "        disagreement_calc = None\n",
    "\n",
    "       \n",
    "        # Initialize disagreement calculation\n",
    "        if both_local:\n",
    "            disagreement_calc = Disagreement(explanations1[project_id], explanations2[project_id])\n",
    "        else:\n",
    "            disagreement_calc = Disagreement(explanations2, explanations1[project_id])\n",
    "        \n",
    "        if debug:\n",
    "            print(\"Initial Explanation 1 \\n\", disagreement_calc.sorted_explanation1[:k])\n",
    "            print(\"Initial Explanation 2 \\n\", disagreement_calc.sorted_explanation2[:k])\n",
    "            \n",
    "        if method==\"max\":\n",
    "            max_compactor = MaxCompactor(categorical_cols)\n",
    "            disagreement_calc.compact_features(max_compactor)\n",
    "            \n",
    "            \n",
    "        elif method == \"activated\" and raw_data is not None:\n",
    "            activated_features = {}\n",
    "            for feature in categorical_cols:\n",
    "                activated_features[feature] = f\"{feature}_{raw_data[raw_data['Project ID'] == project_id ][feature].values[0]}\"\n",
    "            activated_compactor = ActivatedCompactor(activated_features)\n",
    "            disagreement_calc.compact_features(activated_compactor)\n",
    "            \n",
    "        elif method == \"maxnonactivated\" and raw_data is not None:\n",
    "            activated_features = {}\n",
    "            for feature in categorical_cols:\n",
    "                activated_features[feature] = f\"{feature}_{raw_data[raw_data['Project ID'] == project_id ][feature].values[0]}\"\n",
    "            max_non_activated_compactor = MaxNonActivatedCompactor(activated_features)\n",
    "            disagreement_calc.compact_features(max_non_activated_compactor)\n",
    "            \n",
    "        if debug:\n",
    "            print(\"After Compact Explanation 1 \\n\",disagreement_calc.sorted_explanation1[:k])\n",
    "            print(\"After Compact Explanation 2 \\n\",disagreement_calc.sorted_explanation2[:k])\n",
    "            \n",
    "            \n",
    "        disagreement = disagreement_calc.get_disagreement(k, features_F)\n",
    "        \n",
    "        if debug:\n",
    "            print(\"Disagreement : \", disagreement)\n",
    "        \n",
    "        for key in list(disagreement_mean.keys()):\n",
    "            if disagreement[key] == None:\n",
    "                raise ValueError(f\"The value for key '{key}' in disagreement_mean is None.\")\n",
    "            disagreement_mean[key] += disagreement[key]\n",
    "        \n",
    "        if debug:\n",
    "            print(\"****************************************\")\n",
    "\n",
    "    for key in list(disagreement_mean.keys()):\n",
    "        disagreement_mean[key] = round(disagreement_mean[key] / len(explanations1.keys()),3)\n",
    "    \n",
    "    if debug:\n",
    "        print(\"*********************************************\")\n",
    "        print(disagreement_mean)\n",
    "        print(\"*********************************************\")\n",
    "\n",
    "    \n",
    "    return disagreement_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6780f2e2-349a-4895-9c04-981b86946068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_feat(model_path, model_name, model_type):\n",
    "    # Load the model\n",
    "    model = None\n",
    "    importance = None\n",
    "    feat_names = None\n",
    "    \n",
    "    if model_type == 'nn':\n",
    "        model_file_path = f'{model_path}{model_name}' \n",
    "        model = keras.models.load_model(model_file_path)\n",
    "        # Skip the rest\n",
    "\n",
    "    elif model_type == 'lgbm':\n",
    "        model_file_path = f'{model_path}{model_name}'\n",
    "        model = joblib.load(model_file_path)\n",
    "        # Load the feature importance array\n",
    "        importance = model.feature_importances_\n",
    "        # Get the feature names\n",
    "        feat_names = model.feature_name_\n",
    "\n",
    "    elif model_type == 'lr':\n",
    "        model_file_path = f'{model_path}{model_name}'\n",
    "        model = joblib.load(model_file_path)\n",
    "        # Load the feature importance array\n",
    "        importance = model.coef_[0]\n",
    "        # Get the feature names\n",
    "        feat_names = model.feature_names_in_\n",
    "    \n",
    "    else:\n",
    "        model_file_path = f'{model_path}{model_name}'\n",
    "        model = joblib.load(model_file_path)\n",
    "        # Load the feature importance array\n",
    "        importance = model.feature_importances_\n",
    "        # Get the feature names\n",
    "        feat_names = model.feature_names_in_\n",
    "    \n",
    "    return importance, feat_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32a40580-f0b5-4ccd-8209-cefd30559231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to select the top k features and plot\n",
    "def select_top_features(importance, feat_names):\n",
    "    # Create df and sort\n",
    "    df = pd.DataFrame({\"Feature\": feat_names, \"Importance\": importance})\n",
    "    #df_sorted = df.sort_values(\"Importance\", ascending=False)\n",
    "    df_sorted = df.reindex(df.Importance.abs().sort_values(ascending=False).index)\n",
    "    return df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95143e09-79a6-454a-9843-379d5c8b2c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Project Cost', 0.21832490517874864],\n",
       "       ['Resource Cost', 0.10584395574442541],\n",
       "       ['School Success Rate', 0.06696661597145076],\n",
       "       ...,\n",
       "       ['Project Subject Subcategory Tree_Special Needs, Warmth, Care & Hunger',\n",
       "        0.0],\n",
       "       ['Project Subject Subcategory Tree_Team Sports, Visual Arts', 0.0],\n",
       "       ['Project Subject Subcategory Tree_Gym & Fitness, Warmth, Care & Hunger',\n",
       "        0.0]], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "global_importance, feat_names = load_model_and_feat(art_root+model_path, model_name, model_type)\n",
    "#print(global_importance, feat_names)\n",
    "global_explanation = select_top_features(global_importance, feat_names)\n",
    "global_explanation.values\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9f1b715-7fd1-415c-8657-7143fe94aeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty df - define the column names\n",
    "df = pd.DataFrame(columns=['Explanations', 'Compactor', 'Model', \n",
    "                           'Feature(10%)', 'Feature(20%)', \n",
    "                           'Rank(10%)', 'Rank(20%)', \n",
    "                           'Sign(10%)', 'Sign(20%)', \n",
    "                           'SignedRank(10%)', 'SignedRank(20%)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3e0587-058a-453f-bb8d-ecd8cd8c4879",
   "metadata": {},
   "source": [
    "Local vs local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e77ab4ea-9f21-4f69-b9ca-14c10623dc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature_agreement': 0.146, 'rank_agreement': 0.007, 'sign_agreement': 0.08, 'signed_rank_agreement': 0.006}\n",
      "{'feature_agreement': 0.715, 'rank_agreement': 0.433, 'sign_agreement': 0.626, 'signed_rank_agreement': 0.388}\n",
      "{'feature_agreement': 0.525, 'rank_agreement': 0.334, 'sign_agreement': 0.449, 'signed_rank_agreement': 0.301}\n",
      "{'feature_agreement': 0.715, 'rank_agreement': 0.433, 'sign_agreement': 0.627, 'signed_rank_agreement': 0.389}\n",
      "{'feature_agreement': 0.039, 'rank_agreement': 0.003, 'sign_agreement': 0.028, 'signed_rank_agreement': 0.003}\n",
      "{'feature_agreement': 0.126, 'rank_agreement': 0.055, 'sign_agreement': 0.121, 'signed_rank_agreement': 0.055}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m disagreement_max_comp_top_10_perc \u001b[38;5;241m=\u001b[39m disagreement_average(exp_combined_1, exp_combined_2, \u001b[38;5;28;01mTrue\u001b[39;00m, top_10_perc_compressed, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, processed)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(disagreement_max_comp_top_10_perc)\n\u001b[0;32m----> 9\u001b[0m disagreement_act_comp_top_10_perc \u001b[38;5;241m=\u001b[39m \u001b[43mdisagreement_average\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_combined_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_combined_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_10_perc_compressed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mactivated\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(disagreement_act_comp_top_10_perc)\n\u001b[1;32m     11\u001b[0m disagreement_maxnonact_comp_top_10_perc \u001b[38;5;241m=\u001b[39m disagreement_average(exp_combined_1, exp_combined_2, \u001b[38;5;28;01mTrue\u001b[39;00m, top_10_perc_compressed, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxnonactivated\u001b[39m\u001b[38;5;124m'\u001b[39m, processed)\n",
      "Cell \u001b[0;32mIn[11], line 36\u001b[0m, in \u001b[0;36mdisagreement_average\u001b[0;34m(explanations1, explanations2, both_local, k, features_F, method, raw_data, debug)\u001b[0m\n\u001b[1;32m     34\u001b[0m activated_features \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m categorical_cols:\n\u001b[0;32m---> 36\u001b[0m     activated_features[feature] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeature\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mraw_data[\u001b[43mraw_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mProject ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mproject_id\u001b[49m\u001b[38;5;250m \u001b[39m][feature]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     37\u001b[0m activated_compactor \u001b[38;5;241m=\u001b[39m ActivatedCompactor(activated_features)\n\u001b[1;32m     38\u001b[0m disagreement_calc\u001b[38;5;241m.\u001b[39mcompact_features(activated_compactor)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/series.py:5804\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   5801\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   5802\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 5804\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5806\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/ops/array_ops.py:346\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 346\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/ops/array_ops.py:131\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m    129\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mvec_compare(x\u001b[38;5;241m.\u001b[39mravel(), y\u001b[38;5;241m.\u001b[39mravel(), op)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 131\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mlibops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalar_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for key_pair in list(itertools.combinations(xai_keys_list, 2)):\n",
    "    exp_combined_1 = explanations[fold][key_pair[0]]['top'] | explanations[fold][key_pair[0]]['bottom']\n",
    "    exp_combined_2 = explanations[fold][key_pair[1]]['top'] | explanations[fold][key_pair[1]]['bottom']\n",
    "\n",
    "\n",
    "    # Top 10%\n",
    "    disagreement_no_comp_top_10_perc = disagreement_average(exp_combined_1, exp_combined_2, True, top_10_perc_uncompressed, None)\n",
    "    disagreement_max_comp_top_10_perc = disagreement_average(exp_combined_1, exp_combined_2, True, top_10_perc_compressed, None, 'max', processed)\n",
    "    disagreement_act_comp_top_10_perc = disagreement_average(exp_combined_1, exp_combined_2, True, top_10_perc_compressed, None, 'activated', processed)\n",
    "    disagreement_maxnonact_comp_top_10_perc = disagreement_average(exp_combined_1, exp_combined_2, True, top_10_perc_compressed, None, 'maxnonactivated', processed)\n",
    "\n",
    "    # Top 20%\n",
    "    disagreement_no_comp_top_20_perc = disagreement_average(exp_combined_1, exp_combined_2, True, top_20_perc_uncompressed, None)\n",
    "    disagreement_max_comp_top_20_perc = disagreement_average(exp_combined_1, exp_combined_2, True, top_20_perc_compressed, None, 'max', processed)\n",
    "    disagreement_act_comp_top_20_perc = disagreement_average(exp_combined_1, exp_combined_2, True, top_20_perc_compressed, None, 'activated', processed)\n",
    "    disagreement_maxnonact_comp_top_20_perc = disagreement_average(exp_combined_1, exp_combined_2, True, top_20_perc_compressed, None, 'maxnonactivated', processed)\n",
    "\n",
    "    # Add to dataframe\n",
    "    df.loc[len(df)] = {'Explanations' : f'{key_pair[0]}_vs_{key_pair[1]}', \n",
    "                    'Compactor' : 'No compactor', \n",
    "                    'Model' : model_type_save, \n",
    "                    'Feature(10%)': disagreement_no_comp_top_10_perc['feature_agreement'], \n",
    "                    'Feature(20%)': disagreement_no_comp_top_20_perc['feature_agreement'], \n",
    "                    'Rank(10%)': disagreement_no_comp_top_10_perc['rank_agreement'], \n",
    "                    'Rank(20%)': disagreement_no_comp_top_20_perc['rank_agreement'], \n",
    "                    'Sign(10%)': disagreement_no_comp_top_10_perc['sign_agreement'], \n",
    "                    'Sign(20%)': disagreement_no_comp_top_20_perc['sign_agreement'], \n",
    "                    'SignedRank(10%)': disagreement_no_comp_top_10_perc['signed_rank_agreement'], \n",
    "                    'SignedRank(20%)': disagreement_no_comp_top_20_perc['signed_rank_agreement']}\n",
    "    \n",
    "    df.loc[len(df)] = {'Explanations' : f'{key_pair[0]}_vs_{key_pair[1]}', \n",
    "                    'Compactor' : 'Max compactor', \n",
    "                    'Model' : model_type_save, \n",
    "                    'Feature(10%)': disagreement_max_comp_top_10_perc['feature_agreement'], \n",
    "                    'Feature(20%)': disagreement_max_comp_top_20_perc['feature_agreement'], \n",
    "                    'Rank(10%)': disagreement_max_comp_top_10_perc['rank_agreement'], \n",
    "                    'Rank(20%)': disagreement_max_comp_top_20_perc['rank_agreement'], \n",
    "                    'Sign(10%)': disagreement_max_comp_top_10_perc['sign_agreement'], \n",
    "                    'Sign(20%)': disagreement_max_comp_top_20_perc['sign_agreement'], \n",
    "                    'SignedRank(10%)': disagreement_max_comp_top_10_perc['signed_rank_agreement'], \n",
    "                    'SignedRank(20%)': disagreement_max_comp_top_20_perc['signed_rank_agreement']}\n",
    "    \n",
    "    df.loc[len(df)] = {'Explanations' : f'{key_pair[0]}_vs_{key_pair[1]}', \n",
    "                    'Compactor' : 'Activated compactor', \n",
    "                    'Model' : model_type_save, \n",
    "                    'Feature(10%)': disagreement_act_comp_top_10_perc['feature_agreement'], \n",
    "                    'Feature(20%)': disagreement_act_comp_top_20_perc['feature_agreement'], \n",
    "                    'Rank(10%)': disagreement_act_comp_top_10_perc['rank_agreement'], \n",
    "                    'Rank(20%)': disagreement_act_comp_top_20_perc['rank_agreement'], \n",
    "                    'Sign(10%)': disagreement_act_comp_top_10_perc['sign_agreement'], \n",
    "                    'Sign(20%)': disagreement_act_comp_top_20_perc['sign_agreement'], \n",
    "                    'SignedRank(10%)': disagreement_act_comp_top_10_perc['signed_rank_agreement'], \n",
    "                    'SignedRank(20%)': disagreement_act_comp_top_20_perc['signed_rank_agreement']}\n",
    "\n",
    "    df.loc[len(df)] = {'Explanations' : f'{key_pair[0]}_vs_{key_pair[1]}', \n",
    "                    'Compactor' : 'Non-activated max compactor', \n",
    "                    'Model' : model_type_save, \n",
    "                    'Feature(10%)': disagreement_maxnonact_comp_top_10_perc['feature_agreement'], \n",
    "                    'Feature(20%)': disagreement_maxnonact_comp_top_20_perc['feature_agreement'], \n",
    "                    'Rank(10%)': disagreement_maxnonact_comp_top_10_perc['rank_agreement'], \n",
    "                    'Rank(20%)': disagreement_maxnonact_comp_top_20_perc['rank_agreement'], \n",
    "                    'Sign(10%)': disagreement_maxnonact_comp_top_10_perc['sign_agreement'], \n",
    "                    'Sign(20%)': disagreement_maxnonact_comp_top_20_perc['sign_agreement'], \n",
    "                    'SignedRank(10%)': disagreement_maxnonact_comp_top_10_perc['signed_rank_agreement'], \n",
    "                    'SignedRank(20%)': disagreement_maxnonact_comp_top_20_perc['signed_rank_agreement']}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10996627-508b-45ea-84eb-8909cbc44316",
   "metadata": {},
   "source": [
    "Global vs local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8178c2f9-b79c-4643-a8e5-c42f49041a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for local_key in xai_keys_list:\n",
    "    exp_combined = explanations[fold][local_key]['top'] | explanations[fold][local_key]['bottom']\n",
    "\n",
    "    # Top 10%\n",
    "    disagreement_no_comp_top_10_perc = disagreement_average(exp_combined, global_explanation.values, False, top_10_perc_uncompressed, None)\n",
    "    disagreement_max_comp_top_10_perc = disagreement_average(exp_combined, global_explanation.values, False, top_10_perc_compressed, None, 'max', processed)\n",
    "    disagreement_act_comp_top_10_perc = disagreement_average(exp_combined, global_explanation.values, False, top_10_perc_compressed, None, 'activated', processed)\n",
    "    disagreement_maxnonact_comp_top_10_perc = disagreement_average(exp_combined, global_explanation.values, False, top_10_perc_compressed, None, 'maxnonactivated', processed)\n",
    "\n",
    "    # Top 20%\n",
    "    disagreement_no_comp_top_20_perc = disagreement_average(exp_combined, global_explanation.values, False, top_20_perc_uncompressed, None)\n",
    "    disagreement_max_comp_top_20_perc = disagreement_average(exp_combined, global_explanation.values, False, top_20_perc_compressed, None, 'max', processed)\n",
    "    disagreement_act_comp_top_20_perc = disagreement_average(exp_combined, global_explanation.values, False, top_20_perc_compressed, None, 'activated', processed)\n",
    "    disagreement_maxnonact_comp_top_20_perc = disagreement_average(exp_combined, global_explanation.values, False, top_20_perc_compressed, None, 'maxnonactivated', processed)\n",
    "\n",
    "    # Add to dataframe\n",
    "    df.loc[len(df)] = {'Explanations' : f'Global_vs_{local_key}', \n",
    "                    'Compactor' : 'No compactor', \n",
    "                    'Model' : model_type_save, \n",
    "                    'Feature(10%)': disagreement_no_comp_top_10_perc['feature_agreement'], \n",
    "                    'Feature(20%)': disagreement_no_comp_top_20_perc['feature_agreement'], \n",
    "                    'Rank(10%)': disagreement_no_comp_top_10_perc['rank_agreement'], \n",
    "                    'Rank(20%)': disagreement_no_comp_top_20_perc['rank_agreement'], \n",
    "                    'Sign(10%)': disagreement_no_comp_top_10_perc['sign_agreement'], \n",
    "                    'Sign(20%)': disagreement_no_comp_top_20_perc['sign_agreement'], \n",
    "                    'SignedRank(10%)': disagreement_no_comp_top_10_perc['signed_rank_agreement'], \n",
    "                    'SignedRank(20%)': disagreement_no_comp_top_20_perc['signed_rank_agreement']}\n",
    "    \n",
    "    df.loc[len(df)] = {'Explanations' : f'Global_vs_{local_key}', \n",
    "                    'Compactor' : 'Max compactor', \n",
    "                    'Model' : model_type_save, \n",
    "                    'Feature(10%)': disagreement_max_comp_top_10_perc['feature_agreement'], \n",
    "                    'Feature(20%)': disagreement_max_comp_top_20_perc['feature_agreement'], \n",
    "                    'Rank(10%)': disagreement_max_comp_top_10_perc['rank_agreement'], \n",
    "                    'Rank(20%)': disagreement_max_comp_top_20_perc['rank_agreement'], \n",
    "                    'Sign(10%)': disagreement_max_comp_top_10_perc['sign_agreement'], \n",
    "                    'Sign(20%)': disagreement_max_comp_top_20_perc['sign_agreement'], \n",
    "                    'SignedRank(10%)': disagreement_max_comp_top_10_perc['signed_rank_agreement'], \n",
    "                    'SignedRank(20%)': disagreement_max_comp_top_20_perc['signed_rank_agreement']}\n",
    "\n",
    "    df.loc[len(df)] = {'Explanations' : f'Global_vs_{local_key}', \n",
    "                    'Compactor' : 'Activated compactor', \n",
    "                    'Model' : model_type_save, \n",
    "                    'Feature(10%)': disagreement_act_comp_top_10_perc['feature_agreement'], \n",
    "                    'Feature(20%)': disagreement_act_comp_top_20_perc['feature_agreement'], \n",
    "                    'Rank(10%)': disagreement_act_comp_top_10_perc['rank_agreement'], \n",
    "                    'Rank(20%)': disagreement_act_comp_top_20_perc['rank_agreement'], \n",
    "                    'Sign(10%)': disagreement_act_comp_top_10_perc['sign_agreement'], \n",
    "                    'Sign(20%)': disagreement_act_comp_top_20_perc['sign_agreement'], \n",
    "                    'SignedRank(10%)': disagreement_act_comp_top_10_perc['signed_rank_agreement'], \n",
    "                    'SignedRank(20%)': disagreement_act_comp_top_20_perc['signed_rank_agreement']}\n",
    "\n",
    "    \n",
    "    df.loc[len(df)] = {'Explanations' : f'Global_vs_{local_key}', \n",
    "                    'Compactor' : 'Non-activated max compactor', \n",
    "                    'Model' : model_type_save, \n",
    "                    'Feature(10%)': disagreement_maxnonact_comp_top_10_perc['feature_agreement'], \n",
    "                    'Feature(20%)': disagreement_maxnonact_comp_top_20_perc['feature_agreement'], \n",
    "                    'Rank(10%)': disagreement_maxnonact_comp_top_10_perc['rank_agreement'], \n",
    "                    'Rank(20%)': disagreement_maxnonact_comp_top_20_perc['rank_agreement'], \n",
    "                    'Sign(10%)': disagreement_maxnonact_comp_top_10_perc['sign_agreement'], \n",
    "                    'Sign(20%)': disagreement_maxnonact_comp_top_20_perc['sign_agreement'], \n",
    "                    'SignedRank(10%)': disagreement_maxnonact_comp_top_10_perc['signed_rank_agreement'], \n",
    "                    'SignedRank(20%)': disagreement_maxnonact_comp_top_20_perc['signed_rank_agreement']}\n",
    "\n",
    "'''    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2990832f-a98d-4273-96d8-dcb9edb3baaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save df as csv\n",
    "df.to_csv(f'{save_path}agreement_all_exp_{model_type}_{fold}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
