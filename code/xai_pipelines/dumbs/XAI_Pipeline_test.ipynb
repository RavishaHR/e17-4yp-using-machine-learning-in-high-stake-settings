{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bded8452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32abd836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import lime\n",
    "from lime import lime_tabular\n",
    "import shap\n",
    "\n",
    "import json\n",
    "from typing import Union\n",
    "from datetime import datetime as dt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ddedc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/storage/scratch/e17-4yp-xai/Documents/artefact_backup/backup_1M_inputs_rand_frst/model_outputs/artifacts/random_forest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f705e35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = sorted(['train_fold_1_2017-01-06.csv', 'train_fold_2_2016-09-08.csv', 'train_fold_3_2016-05-11.csv', 'train_fold_4_2016-01-12.csv', 'train_fold_5_2015-09-14.csv' , 'train_fold_6_2015-05-17.csv'], reverse=True)\n",
    "test_files = [ 'test_fold_6_2015-05-17.csv' , 'test_fold_5_2015-09-14.csv', 'test_fold_4_2016-01-12.csv', 'test_fold_3_2016-05-11.csv',  'test_fold_2_2016-09-08.csv', 'test_fold_1_2017-01-06.csv']\n",
    "\n",
    "\n",
    "test_pred = ['test_prediction_fold_6_2015-05-17.csv' , 'test_prediction_fold_5_2015-09-14.csv', 'test_prediction_fold_4_2016-01-12.csv', 'test_prediction_fold_3_2016-05-11.csv', 'test_prediction_fold_2_2016-09-08.csv' , 'test_prediction_fold_1_2017-01-06.csv' ]\n",
    "\n",
    "models = sorted([\"random_forest_fold_1_2017-01-06.pkl\", \"random_forest_fold_2_2016-09-08.pkl\", \"random_forest_fold_3_2016-05-11.pkl\", \"random_forest_fold_4_2016-01-12.pkl\", \"random_forest_fold_5_2015-09-14.pkl\", \"random_forest_fold_6_2015-05-17.pkl\" ], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a691e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ROOT = \"/storage/scratch/e17-4yp-xai/Documents/e17-4yp-using-machine-learning-in-high-stake-settings/code/\"\n",
    "ROOT = \"./\"\n",
    "DATA_SOURCE = ROOT + \"data/DsDnsPrScTch.csv\"\n",
    "DATA_DEST = ROOT + \"processed_data/\"\n",
    "MODEL_DEST = ROOT + \"trained_models/\"\n",
    "IMAGE_DEST = ROOT + \"model_outputs/figures/\"\n",
    "LIME_DEST = ROOT + \"model_outputs/lime/\"\n",
    "SHAP_DEST = ROOT + \"model_outputs/shap/\"\n",
    "TREESHAP_DEST = ROOT + \"model_outputs/treeshap/\"\n",
    "K_PROJECTS_DEST = IMAGE_DEST + \"k_projects/\"\n",
    "ROC_CURVE_DEST = IMAGE_DEST + \"roc_curve/\"\n",
    "P_VS_R_CURVE_DEST = IMAGE_DEST + \"pr_curve/\"\n",
    "ARTIFACTS_PATH = ROOT + \"model_outputs/artifacts/\"\n",
    "\n",
    "INFO_DEST = ROOT+\"model_outputs/info/\"\n",
    "# MODEL_RUN_LOG_PATH = INFO_DEST + \"model_run_log.py\"\n",
    "PROCESSED_DATA_PATH = DATA_DEST + \"labelled_final_data.csv\"\n",
    "\n",
    "LOAD_PROCESSED_DATA_FLAG = False\n",
    "MAX_ROWS = 400000  # if you change this, updating LOAD_PROCESSED_DATA_FLAG to False is required\n",
    "\n",
    "FIXED_KVAL = 1000\n",
    "\n",
    "# To label data\n",
    "DONATION_PERIOD = 30\n",
    "THRESHOLD_RATIO = 0.4\n",
    "\n",
    "TRAINING_WINDOW = DONATION_PERIOD * 4\n",
    "\n",
    "MAX_TIME = \"2016-04-01 00:00:00\"\n",
    "MIN_TIME = \"2013-05-01 00:00:00\"\n",
    "\n",
    "TEST_SIZE = 30\n",
    "TRAIN_SIZE = TEST_SIZE*6\n",
    "LEAK_OFFSET = TEST_SIZE*4\n",
    "WINDOW = TEST_SIZE + TRAIN_SIZE + 2*LEAK_OFFSET\n",
    "\n",
    "\n",
    "DATE_COLS = [\"Teacher First Project Posted Date\", \"Project Fully Funded Date\", \"Project Expiration Date\",\n",
    "             \"Project Posted Date\", \"Donation Received Date\"]\n",
    "CATEGORICAL_COLS = [\"Project Type\", \"Project Subject Category Tree\", \"Project Subject Subcategory Tree\",\n",
    "                    \"Project Grade Level Category\", \"Project Resource Category\", \"School Metro Type\",\n",
    "                    \"School State\", \"School County\", \"Teacher Prefix\", \"School Name\", \"School City\", \"School District\"]\n",
    "\n",
    "TRAINING_FEATURES = [\"Project ID\", \"Project Posted Date\", \"Project Type\", \"Project Subject Category Tree\", \"Project Cost\",\n",
    "                     \"Project Subject Subcategory Tree\", \"Project Grade Level Category\", \"Project Resource Category\",\n",
    "                     \"School Metro Type\", \"School Percentage Free Lunch\", \"School State\", \"School County\",\n",
    "                     \"School Name\", \"School City\", \"School District\",\n",
    "                     \"Teacher Prefix\", \"Teacher Project Posted Sequence\"]\n",
    "#   \"Statement Error Ratio\", \"Title Essay Relativity\", \"Description Essay Relativity\"]\n",
    "\n",
    "VARIABLES_TO_SCALE = [\"School Percentage Free Lunch\", \"Teacher Project Posted Sequence\", \"Project Cost\",\n",
    "                      'Teacher Success Rate', 'School City Success Rate', 'School Success Rate',\n",
    "                      'School County Success Rate', 'Project Count in State']\n",
    "# \"Statement Error Ratio\", \"Title Essay Relativity\", \"Description Essay Relativity\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dfaad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def save_model(path, file_name, model):\n",
    "    file_path = path + file_name\n",
    "    pickle.dump(model, file=open(file_path, \"wb\"))\n",
    "\n",
    "\n",
    "def load_model(model_file_path):\n",
    "    return pickle.load(open(model_file_path, 'rb'))\n",
    "\n",
    "def log_intermediate_output_to_file(path, file_name, log_info: Union[list, dict, str]):\n",
    "    file_path = path + file_name\n",
    "    json_data = json.dumps(log_info, indent=2)\n",
    "    time = dt.now()\n",
    "    with open(file_path, 'a') as file:\n",
    "        file.write(f\"\\nlog {str(time.strftime('%Y-%m-%d %H:%M:%S'))}\\n{json_data}\\n\")\n",
    "\n",
    "\n",
    "def create_dirs(models=None):\n",
    "    if not models:\n",
    "        models = ['decision_tree', 'log_reg', 'random_forest', 'svm']\n",
    "    paths = [\n",
    "        config.ARTIFACTS_PATH+model_dir+'/' for model_dir in models\n",
    "    ] + [\n",
    "        config.IMAGE_DEST+model_dir+'/' for model_dir in models\n",
    "    ] + [\n",
    "        config.IMAGE_DEST+'k_projects/'+model_dir+'/' for model_dir in models\n",
    "    ] + [\n",
    "        config.INFO_DEST+model_dir+'/' for model_dir in models\n",
    "    ] + [\n",
    "        config.ROOT+'trained_models/', config.ROOT+'processed_data/'\n",
    "    ]\n",
    "    for path in paths:\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "    print(f\"{len(paths)} directories created...\")\n",
    "    print('Created all directories!')\n",
    "\n",
    "\n",
    "def create_random_forest_parameters(\n",
    "    max_depths=[2, 3],\n",
    "    n_estimators=[20, 100],\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=2,\n",
    ") -> list:\n",
    "    parameters_list = []\n",
    "    # create various combinations of the above attributes\n",
    "    for max_depth in max_depths:\n",
    "        for n in n_estimators:\n",
    "            parameters = {\n",
    "                'criterion': \"gini\",\n",
    "                'max_depth': max_depth,\n",
    "                'n_estimators': n,\n",
    "                'min_samples_split': min_samples_split,\n",
    "                'min_samples_leaf': min_samples_leaf\n",
    "            }\n",
    "            parameters_list.append(parameters)\n",
    "    return parameters_list\n",
    "\n",
    "\n",
    "def create_logistic_regression_parameters(\n",
    "        solver=\"saga\",\n",
    "        max_iters=[100, 200],\n",
    "        penalties=[\"l1\", \"l2\"]\n",
    ") -> list:\n",
    "    parameters_list = []\n",
    "    for penalty in penalties:\n",
    "        for max_iter in max_iters:\n",
    "            parameters = {\n",
    "                'penalty': penalty,\n",
    "                'solver': solver,\n",
    "                'max_iter': max_iter\n",
    "            }\n",
    "            parameters_list.append(parameters)\n",
    "\n",
    "    return parameters_list\n",
    "\n",
    "\n",
    "def create_classification_models(\n",
    "        random_forest_parameters_list: list,\n",
    "        logistic_regression_parameters_list: list\n",
    ") -> list:\n",
    "    models_list = []\n",
    "    i = 1\n",
    "    for parameters in random_forest_parameters_list:\n",
    "        new_model = RandomForestClassifier(**parameters)\n",
    "        models_list.append({\n",
    "            'model_name': f'random_forest_{i}',\n",
    "            'model': new_model,\n",
    "            'type': 'non-linear',\n",
    "            'parameters': parameters\n",
    "        })\n",
    "        i += 1\n",
    "\n",
    "    i = 1\n",
    "    for parameters in logistic_regression_parameters_list:\n",
    "        new_model = LogisticRegression(**parameters)\n",
    "        models_list.append({\n",
    "            'model_name': f'logistic_regression_{i}',\n",
    "            'model': new_model,\n",
    "            'type': 'linear',\n",
    "            'parameters': parameters\n",
    "        })\n",
    "        i += 1\n",
    "    cost_sorted_k_baseline_model = {\n",
    "        'model_name': 'cost_sorted_k_baseline_model',\n",
    "        'model': None,\n",
    "        'type': 'baseline'\n",
    "    }\n",
    "    random_k_baseline_model = {\n",
    "        'model_name': 'random_k_baseline_model',\n",
    "        'model': None,\n",
    "        'type': 'baseline'\n",
    "    }\n",
    "    models_list.append(cost_sorted_k_baseline_model)\n",
    "    models_list.append(random_k_baseline_model)\n",
    "\n",
    "    return models_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef2a8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def save_lime_explanation(exp, instance_loc, model_name, position, project_id,fold):\n",
    "\n",
    "    # exp.show_in_notebook(show_table=True)\n",
    "    # Save as html file\n",
    "    filepath = f\"{LIME_DEST}{fold}/{position}\"\n",
    "    try:\n",
    "        os.makedirs(filepath, exist_ok = True)\n",
    "        print(\"Directory '%s' created successfully\" %filepath)\n",
    "    except OSError as error:\n",
    "        print(\"Directory '%s' can not be created\")\n",
    "    \n",
    "    exp.save_to_file(f'{LIME_DEST}{fold}/{position}/lime_exp_{project_id}_{model_name}.html')\n",
    "\n",
    "    # Save as pyplot figure\n",
    "    plt.cla()\n",
    "    exp.as_pyplot_figure()\n",
    "    plt.savefig(f'{LIME_DEST}{fold}/{position}/lime_exp_{project_id}_{model_name}.png')\n",
    "    plt.show()\n",
    "\n",
    "    return\n",
    "\n",
    "def get_lime_explanation(x_train, x_test, top_instance_loc_list, bottom_instance_loc_list, class_names, mode, model, model_name, fold):\n",
    "\n",
    "    # take the list of instances and save the explaination of each instance.\n",
    "    # LIME: define the explainer\n",
    "    # Ex: mode = 'classification' or 'regression'\n",
    "    #     class_names = ['0', '1']\n",
    "\n",
    "    categorical_feature_names = x_train.dtypes[x_train.dtypes==bool].index.to_list()\n",
    "    categorical_feature_index = [x_train.columns.get_loc(col) for col in categorical_feature_names]\n",
    "    \n",
    "    \n",
    "    explainer_lime = lime_tabular.LimeTabularExplainer(\n",
    "        training_data=np.array(x_train),\n",
    "        feature_names=x_train.columns,\n",
    "        categorical_features = categorical_feature_index,\n",
    "        class_names=class_names,\n",
    "        mode=mode\n",
    "    )\n",
    "    \n",
    "    \n",
    "    for instance_loc in top_instance_loc_list:\n",
    "        # Select instance\n",
    "        instance = x_test.iloc[instance_loc]\n",
    "        # Find its Project ID\n",
    "        project_id = instance[\"Project ID\"]\n",
    "        # Drop the Project ID value from the instance since its not a feature\n",
    "        instance = instance.drop([\"Project ID\"])\n",
    "        # Get the explanation\n",
    "        exp1 = explainer_lime.explain_instance(\n",
    "            data_row=instance,\n",
    "            predict_fn=model.predict_proba\n",
    "        )\n",
    "        # Save the explanation as a figure\n",
    "        save_lime_explanation(exp1, instance_loc, model_name, \"top\", project_id, fold)\n",
    "        \n",
    "    for instance_loc in bottom_instance_loc_list:\n",
    "        # Select instance \n",
    "        instance = x_test.iloc[instance_loc]\n",
    "        # Find its Project ID\n",
    "        project_id = instance[\"Project ID\"]\n",
    "        # Drop the Project ID value from the instance since its not a feature\n",
    "        instance = instance.drop([\"Project ID\"])\n",
    "        # Get the explanation\n",
    "        exp2 = explainer_lime.explain_instance(\n",
    "            data_row=instance,\n",
    "            predict_fn=model.predict_proba\n",
    "        )\n",
    "        # Save the explanation as a figure\n",
    "        save_lime_explanation(exp2, instance_loc, model_name, \"bottom\", project_id, fold)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadae52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_shap_explanation(x_train, x_test, top_instance_loc_list, bottom_instance_loc_list, model, model_name, fold):\n",
    "    \n",
    "    \n",
    "\n",
    "    # Define the KernelSHAP explainer\n",
    "    print(\"Kernel Explainer Loading ..... \")\n",
    "    explainer_shap = shap.KernelExplainer(model=model.predict_proba, data=x_train)\n",
    "    \n",
    "    print(\"Top list\")\n",
    "\n",
    "    for i, instance_loc in enumerate(top_instance_loc_list):\n",
    "        print(f\"{i} th  of the instance explanation\")\n",
    "        # Select instance\n",
    "        instance = x_test.iloc[instance_loc]\n",
    "        # Find its Project ID\n",
    "        project_id = instance[\"Project ID\"]\n",
    "        # Drop the Project ID value from the instance since its not a feature\n",
    "        instance = instance.drop([\"Project ID\"])\n",
    "        \n",
    "        # Find the explanation\n",
    "        shap_values = explainer_shap.shap_values(instance)\n",
    "\n",
    "        # Visualize and save\n",
    "        # Can be either 0 or 1 for binary classification\n",
    "        #shap.force_plot(explainer_shap.expected_value[0], shap_values[0], instance)\n",
    "        filepath = f'{SHAP_DEST}{fold}/top/shap_exp_{project_id}_{model_name}.png'\n",
    "        try:\n",
    "            os.makedirs(filepath, exist_ok = True)\n",
    "            print(\"Directory '%s' created successfully\" %filepath)\n",
    "        except OSError as error:\n",
    "            print(\"Directory '%s' can not be created\")\n",
    "        print(f\"Explanation plot for instance {i}\")\n",
    "        shap.force_plot(explainer_shap.expected_value[1], \n",
    "                        shap_values[1], \n",
    "                        instance, \n",
    "                        show=False, \n",
    "                        matplotlib=True, \n",
    "                        text_rotation=45).savefig(filepath, format = \"png\", dpi = 150, bbox_inches = 'tight') \n",
    "        \n",
    "        \n",
    "#                         text_rotation=45).savefig(filepath, format = \"png\", dpi = 150, bbox_inches = 'tight') \n",
    "        \n",
    "    print(\"Bottom list\")\n",
    "    for i, instance_loc in enumerate(bottom_instance_loc_list):\n",
    "        print(f\"{i} th  of the instance explanation\")\n",
    "        # Select instance\n",
    "        instance = x_test.iloc[instance_loc]\n",
    "        # Find its Project ID\n",
    "        project_id = instance[\"Project ID\"]\n",
    "        # Drop the Project ID value from the instance since its not a feature\n",
    "        instance = instance.drop([\"Project ID\"])\n",
    "        # Find the explanation\n",
    "        shap_values = explainer_shap.shap_values(instance)\n",
    "\n",
    "        # Visualize and save\n",
    "        # Can be either 0 or 1 for binary classification\n",
    "        #shap.force_plot(explainer_shap.expected_value[0], shap_values[0], instance)\n",
    "        filepath = f'{SHAP_DEST}{fold}/bottom/shap_exp_{project_id}_{model_name}.png'\n",
    "        try:\n",
    "            os.makedirs(filepath, exist_ok = True)\n",
    "            print(\"Directory '%s' created successfully\" %filepath)\n",
    "        except OSError as error:\n",
    "            print(\"Directory '%s' can not be created\")\n",
    "            \n",
    "        print(f\"Explanation plot for instance {i}\")\n",
    "        shap.force_plot(explainer_shap.expected_value[1], \n",
    "                        shap_values[1], \n",
    "                        instance, \n",
    "                        show=False, \n",
    "                        matplotlib=True, \n",
    "                        text_rotation=45).savefig(filepath, format = \"png\", dpi = 150, bbox_inches = 'tight') \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442ad73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_treeshap_explanation(x_train, x_test, top_instance_loc_list, bottom_instance_loc_list, model, model_name, fold):\n",
    "    \n",
    "#     print(x_train.head())\n",
    "    # Define the KernelSHAP explainer\n",
    "#     explainer_tree = shap.TreeExplainer(model=model, data=x_train, model_output=\"raw\")\n",
    "    explainer_tree = shap.TreeExplainer(model=model, feature_perturbation='tree_path_dependant')\n",
    "\n",
    "    print(\"Top list\")\n",
    "    for i, instance_loc in enumerate(top_instance_loc_list):\n",
    "        print(f\"{i} th  of the instance explanation\")\n",
    "        # Select instance\n",
    "        instance = x_test.iloc[[instance_loc]]\n",
    "        # Find its Project ID\n",
    "        project_id = instance[\"Project ID\"]\n",
    "        # Drop the Project ID value from the instance since its not a feature\n",
    "        instance = instance.drop([\"Project ID\"], axis=1)\n",
    "        # Find the explanation\n",
    "        treeshap_values = explainer_tree.shap_values(instance)\n",
    "\n",
    "        print(f\"Explanation plot for instance {i}\")\n",
    "        # Visualize and save\n",
    "        filepath = f'{TREESHAP_DEST}{fold}/top/treeshap_exp_{project_id}_{model_name}.png'\n",
    "        shap.force_plot(explainer_tree.expected_value[1], \n",
    "                    treeshap_values[1],\n",
    "                    instance,\n",
    "                    show=False, \n",
    "                    matplotlib=True, \n",
    "                    text_rotation=45).savefig(filepath, format = \"png\", dpi = 150, bbox_inches = 'tight')\n",
    "        \n",
    "    \n",
    "    print(\"Bottom list\")\n",
    "    for i, instance_loc in enumerate(bottom_instance_loc_list):\n",
    "        print(f\"{i} th  of the instance explanation\")\n",
    "        # Select instance\n",
    "        instance = x_test.iloc[instance_loc]\n",
    "        # Find its Project ID\n",
    "        project_id = instance[\"Project ID\"]\n",
    "        # Drop the Project ID value from the instance since its not a feature\n",
    "        instance = instance.drop([\"Project ID\"])\n",
    "        # Find the explanation\n",
    "        treeshap_values = explainer_tree.shap_values(instance)\n",
    "\n",
    "        # Visualize and save\n",
    "        filepath = f'{TREESHAP_DEST}{fold}/bottom/treeshap_exp_{project_id}_{model_name}.png'\n",
    "        try:\n",
    "            os.makedirs(filepath, exist_ok = True)\n",
    "            print(\"Directory '%s' created successfully\" %filepath)\n",
    "        except OSError as error:\n",
    "            print(\"Directory '%s' can not be created\")\n",
    "         \n",
    "        print(f\"Explanation plot for instance {i}\")\n",
    "        shap.force_plot(explainer_tree.expected_value[1], \n",
    "                    treeshap_values[1],\n",
    "                    instance,\n",
    "                    show=False, \n",
    "                    matplotlib=True, \n",
    "                    text_rotation=45).savefig(filepath, format = \"png\", dpi = 150, bbox_inches = 'tight')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2884c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "# New pipeline for ruinning the explainations - call this from main\n",
    "def explanations_pipeline(root, model_paths, train_paths, test_paths, pred_paths, model_name):\n",
    "  \"\"\"this pipeline will generate explanations for the given model paths\n",
    "\n",
    "  Args:\n",
    "      root (_type_): This is the root path of the model artifacts\n",
    "      model_paths (_type_): these are the paths to the model artifacts\n",
    "      train_paths (_type_): these are the paths to the train artifacts\n",
    "      test_paths (_type_): these are the paths to the test artifacts\n",
    "      pred_paths (_type_): these are the paths to the prediction artifacts\n",
    "      model_name (str): this is the model name as a string for identification. ex: \"random forest\"\n",
    "      \n",
    "      all the artifacts should be a list of files and should be in the same order\n",
    "  \"\"\"\n",
    "  assert len(train_paths) == len(test_paths), \"There should be same number of train paths and test paths\"\n",
    "  assert len(test_paths) == len(pred_paths), \"There should be same number of predictions paths and test paths\"\n",
    "  assert len(model_paths) == len(test_paths), \"There should be same number of model_paths paths and test paths\"\n",
    "  \n",
    "  for i in range(len(train_paths)):\n",
    "    print(f\"Fold {i} .............................\")\n",
    "    x_train = pd.read_csv(os.path.join(root, train_paths[i]))\n",
    "    x_train_cleaned = x_train.drop([\"Unnamed: 0\", \"Project ID\", \"Label\"], axis=1)\n",
    "\n",
    "    fold1 = pd.read_csv(os.path.join(root,test_paths[i]))\n",
    "    fold_pred =  pd.read_csv(os.path.join(root,  pred_paths[i]))\n",
    "    Fold1 = pd.concat([fold1, fold_pred[\"1\"]],axis=1)\n",
    "    Fold1 = Fold1.drop([\"Unnamed: 0\"],axis=1)\n",
    "    Fold1_sort = Fold1.sort_values([\"1\"], ascending=False)\n",
    "    #Fold1_sort.head()\n",
    "    x_test_with_id = Fold1_sort.drop([ \"Label\", \"1\"],axis=1)\n",
    "\n",
    "    # Select 50 samples each from top and bottom 1000 records\n",
    "    print(\"Sampling the top 50 and bottom 50\")\n",
    "    top_instance_loc_list = random.sample(range(1000), 50)\n",
    "    bottom_instance_loc_list = random.sample(range(x_test_with_id.shape[0]-1000 , x_test_with_id.shape[0]), 50)\n",
    "    # Get the project IDs of those selected records\n",
    "    #top_project_ids = [x_test_with_id._get_value(i, \"Project ID\") for i in top_instance_loc_list]\n",
    "    #bottom_project_ids = [x_test_with_id._get_value(i, \"Project ID\") for i in bottom_instance_loc_list]\n",
    "\n",
    "    # Drop the project ID column\n",
    "    #x_test = x_test_with_id.drop([\"Project ID\"], axis=1)\n",
    "\n",
    "    print(f\"Model {model_paths} is loading\" )\n",
    "\n",
    "    # Load the saved model\n",
    "    model = load_model(os.path.join(root, model_paths[i]))\n",
    "\n",
    "    print(f\"Explanation for  Lime\" )\n",
    "    # Get explanations\n",
    "    get_lime_explanation(x_train_cleaned[:100].astypes(\"float64\"), x_test_with_id, top_instance_loc_list, bottom_instance_loc_list, [\"0\", \"1\"], \"classification\", model, model_name)\n",
    "    print(f\"Explanation for  Kernal Shap\" )\n",
    "    get_shap_explanation(x_train_cleaned[:100].astype(\"float64\"), x_test_with_id, top_instance_loc_list, bottom_instance_loc_list, model, model_name, f\"{i}\") \n",
    "    print(f\"Explanation for  Tree Shap\" )\n",
    "    get_treeshap_explanation(x_train_cleaned[:100].astype(\"float64\"), x_test_with_id, top_instance_loc_list, bottom_instance_loc_list, model, model_name,f\"{i}\") \n",
    "    print(f\"Explanation for  Tree Shap\" )\n",
    "  \n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6393995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explanations_pipeline(root, models, train_files, test_files, test_pred, \"random_forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f472d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations_pipeline(root, models, train_files, test_files, test_pred, \"random_forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3cbd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "root = root\n",
    "model_paths = models\n",
    "test_paths = test_files\n",
    "pred_paths = test_pred\n",
    "\n",
    "model_name = \"random_forest\"\n",
    "fold = \"fold1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf991e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Fold {0} .............................\")\n",
    "x_train = pd.read_csv(os.path.join(root, train_files[0]))\n",
    "x_train_cleaned = x_train.drop([\"Unnamed: 0\", \"Project ID\", \"Label\"], axis=1)\n",
    "\n",
    "fold1 = pd.read_csv(os.path.join(root,test_paths[0]))\n",
    "fold_pred =  pd.read_csv(os.path.join(root,  pred_paths[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddefa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fold1 = pd.concat([fold1, fold_pred[\"1\"]],axis=1)\n",
    "Fold1 = Fold1.drop([\"Unnamed: 0\"],axis=1)\n",
    "Fold1_sort = Fold1.sort_values([\"1\"], ascending=False)\n",
    "#Fold1_sort.head()\n",
    "x_test_with_id = Fold1_sort.drop([ \"Label\"],axis=1)\n",
    "\n",
    "# Select 50 samples each from top and bottom 1000 records\n",
    "print(\"Sampling the top 50 and bottom 50\")\n",
    "top_instance_loc_list = random.sample(range(1000), 50)\n",
    "bottom_instance_loc_list = random.sample(range(x_test_with_id.shape[0]-1000 , x_test_with_id.shape[0]), 50)\n",
    "# Get the project IDs of those selected records\n",
    "#top_project_ids = [x_test_with_id._get_value(i, \"Project ID\") for i in top_instance_loc_list]\n",
    "#bottom_project_ids = [x_test_with_id._get_value(i, \"Project ID\") for i in bottom_instance_loc_list]\n",
    "\n",
    "# Drop the project ID column\n",
    "#x_test = x_test_with_id.drop([\"Project ID\"], axis=1)\n",
    "\n",
    "print(f\"Model {model_paths} is loading\" )\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model(os.path.join(root, model_paths[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91117810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_float = x_train_cleaned.astype(\"float64\")\n",
    "get_shap_explanation(x_train_cleaned[:100].astype(\"float64\"), x_test_with_id.drop([\"1\"], axis=1), top_instance_loc_list, bottom_instance_loc_list, model, \"random\",\"adf\")\n",
    "\n",
    "# x_test_with_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb29952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_float.dtypes\n",
    "\n",
    "def predict_proba_wrapper(model, X):\n",
    "    return model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d60699",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = x_train_cleaned[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14271a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train.astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa27620",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a KernelExplainer\n",
    "explainer = shap.TreeExplainer(model, data=x,feature_perturbation='interventional', model_output=\"probability\")\n",
    "\n",
    "\n",
    "# Calculate SHAP values for a specific instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbf74f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f30844",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test_with_id.drop([\"1\",\"Project ID\" ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555d4dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = x_test.sample(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bca9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3eb89bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_with_id.head()\n",
    "x_test = x_test_with_id\n",
    "instance_loc = top_instance_loc_list[0]\n",
    "# Select instance\n",
    "instance = x_test.iloc[[instance_loc]]\n",
    "# Find its Project ID\n",
    "project_id = instance[\"Project ID\"]\n",
    "# Drop the Project ID value from the instance since its not a feature\n",
    "instance = instance.drop([\"Project ID\"], axis=1)\n",
    "y = instance.pop(\"1\")\n",
    "\n",
    "# # Visualize and save\n",
    "# filepath = f'{TREESHAP_DEST}{fold}/top/treeshap_exp_{project_id}_{model_name}.png'\n",
    "# shap.force_plot(explainer_tree.expected_value[1], \n",
    "#             treeshap_values[1],\n",
    "#             instance,\n",
    "#             show=False, \n",
    "#             matplotlib=True, \n",
    "#             text_rotation=45).savefig(filepath, format = \"png\", dpi = 150, bbox_inches = 'tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3758f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd072be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(instance.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3242a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Find the explanation\n",
    "treeshap_values = explainer_tree.shap_values(X = instance, check_additivity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691b421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = f'{TREESHAP_DEST}{fold}/top'\n",
    "os.makedirs(filepath, exist_ok=True)\n",
    "shap.force_plot(explainer_tree.expected_value[1], \n",
    "            treeshap_values[1],\n",
    "            instance,\n",
    "            show=False, \n",
    "            matplotlib=True, \n",
    "            text_rotation=45).savefig(filepath+\"/test.png\", format = \"png\", dpi = 150, bbox_inches = 'tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a557afd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#     print(x_train.head())\n",
    "# Define the KernelSHAP explainer\n",
    "#     explainer_tree = shap.TreeExplainer(model=model, data=x_train, model_output=\"raw\")\n",
    "\n",
    "instance_loc = top_instance_loc_list[0]\n",
    "    # Select instance\n",
    "\n",
    "\n",
    "instance = x_test.iloc[[instance_loc]]\n",
    "# Find its Project ID\n",
    "project_id = instance[\"Project ID\"]\n",
    "# Drop the Project ID value from the instance since its not a feature\n",
    "instance = instance.drop([\"Project ID\"], axis=1)\n",
    "# Find the explanation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d53dd9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
