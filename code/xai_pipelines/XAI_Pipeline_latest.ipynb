{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bded8452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f5260c-0b55-43d5-a262-ed136043a79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import lime\n",
    "from lime import lime_tabular\n",
    "import shap\n",
    "\n",
    "import json\n",
    "from typing import Union\n",
    "from datetime import datetime as dt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56ba70b-cc62-49bf-9638-0f28fc5a3d14",
   "metadata": {},
   "source": [
    "Define the necessary paths to obtain data sources after running the main pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ddedc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/storage/scratch/e17-4yp-xai/Documents/artefact_backup/backup_1M_inputs_rand_frst/model_outputs/artifacts/random_forest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f705e35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = sorted(['train_fold_1_2017-01-06.csv', 'train_fold_2_2016-09-08.csv', 'train_fold_3_2016-05-11.csv', 'train_fold_4_2016-01-12.csv', 'train_fold_5_2015-09-14.csv' , 'train_fold_6_2015-05-17.csv'], reverse=True)\n",
    "test_files = [ 'test_fold_6_2015-05-17.csv' , 'test_fold_5_2015-09-14.csv', 'test_fold_4_2016-01-12.csv', 'test_fold_3_2016-05-11.csv',  'test_fold_2_2016-09-08.csv', 'test_fold_1_2017-01-06.csv']\n",
    "\n",
    "\n",
    "test_pred = ['test_prediction_fold_6_2015-05-17.csv' , 'test_prediction_fold_5_2015-09-14.csv', 'test_prediction_fold_4_2016-01-12.csv', 'test_prediction_fold_3_2016-05-11.csv', 'test_prediction_fold_2_2016-09-08.csv' , 'test_prediction_fold_1_2017-01-06.csv' ]\n",
    "\n",
    "models = sorted([\"random_forest_fold_1_2017-01-06.pkl\", \"random_forest_fold_2_2016-09-08.pkl\", \"random_forest_fold_3_2016-05-11.pkl\", \"random_forest_fold_4_2016-01-12.pkl\", \"random_forest_fold_5_2015-09-14.pkl\", \"random_forest_fold_6_2015-05-17.pkl\" ], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a691e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### SET PATH\n",
    "# ROOT = \"/storage/scratch/e17-4yp-xai/Documents/e17-4yp-using-machine-learning-in-high-stake-settings/code/\"\n",
    "ROOT = \"./\"\n",
    "LIME_DEST = ROOT + \"model_outputs/lime/\"\n",
    "SHAP_DEST = ROOT + \"model_outputs/shap/\"\n",
    "TREESHAP_DEST = ROOT + \"model_outputs/treeshap/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c075a351-2ffd-4185-858c-66fcca46a057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for testing locally  - comment out when not required \n",
    "root = 'C:/Users/User/random_forest/'\n",
    "train_files = sorted(['train_fold_1_2017-01-06.csv'])\n",
    "test_files = ['test_fold_1_2017-01-06.csv']\n",
    "test_pred = ['test_prediction_fold_1_2017-01-06.csv']\n",
    "models = sorted([\"random_forest_fold_1_2017-01-06.pkl\"])\n",
    "LIME_DEST = root + \"xai_test_results/lime/\"\n",
    "SHAP_DEST = root + \"xai_test_results/kernelshap/\"\n",
    "TREESHAP_DEST = root + \"xai_test_results/treeshap/\"\n",
    "OUTPUT_DEST = root + \"xai_test_results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dfaad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required helper functions\n",
    "\n",
    "def load_model(model_file_path):\n",
    "    return pickle.load(open(model_file_path, 'rb'))\n",
    "\n",
    "def save_json(dict_obj: Union[dict, list], path: str):\n",
    "    writable_json = json.dumps(dict_obj, indent=4)\n",
    "    with open(path, 'w') as file:\n",
    "        file.write(writable_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1affab0d-791c-45dd-ac39-223604a21a09",
   "metadata": {},
   "source": [
    "Functions for LIME, TreeSHAP and KernelSHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef2a8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Functions used to generate LIME explanation and to save the explanation\n",
    "\n",
    "# Function to convert the features in a LIME explanation object to a list of tuples\n",
    "def get_lime_feature_list(exp_object, feat_names):\n",
    "    exp_list = exp_object.as_map().get(1)\n",
    "    exp_list_with_feature_names = [(feat_names[x[0]], x[1]) for x in exp_list]\n",
    "    print(f'exp_list_with_feature_names = {exp_list_with_feature_names}')\n",
    "    return exp_list_with_feature_names\n",
    "\n",
    "def get_lime_feature_list_encoded(exp_object):\n",
    "    exp_list = exp_object.as_map().get(1)\n",
    "    print(f'exp_list = {exp_list}')\n",
    "    return exp_list\n",
    "\n",
    "def save_lime_explanation(exp, instance_loc, model_name, position, project_id,fold):\n",
    "\n",
    "    # exp.show_in_notebook(show_table=True)\n",
    "    # Save as html file\n",
    "    filepath = f\"{LIME_DEST}{fold}/{position}\"\n",
    "    try:\n",
    "        os.makedirs(filepath, exist_ok = True)\n",
    "        print(\"Directory '%s' created successfully\" %filepath)\n",
    "    except OSError as error:\n",
    "        print(\"Directory '%s' can not be created\")\n",
    "\n",
    "    # Saving the explanation as an image\n",
    "    exp.save_to_file(f'{LIME_DEST}{fold}/{position}/lime_exp_{project_id}_{model_name}.html')\n",
    "\n",
    "    # Save as pyplot figure\n",
    "    exp.as_pyplot_figure()\n",
    "    plt.savefig(f'{LIME_DEST}{fold}/{position}/lime_exp_{project_id}_{model_name}.png')\n",
    "    print(f\"Saving lime exp for {project_id}_{model_name}\")\n",
    "    plt.show()\n",
    "    plt.cla()\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "# Function to generate explanations for a list of instances\n",
    "def get_lime_for_list(instance_loc_list, x_test, explainer_lime, model, model_name, list_type, fold, num_of_feat):\n",
    "\n",
    "    # Dictionary used to save the explanation objects\n",
    "    exp_objects = {}\n",
    "    exp_as_list_objects = {}\n",
    "    \n",
    "    for instance_loc in instance_loc_list:\n",
    "        # Select instance\n",
    "        instance = x_test.iloc[instance_loc]\n",
    "        # Find its Project ID\n",
    "        project_id = instance[\"Project ID\"]\n",
    "        # Drop the Project ID value from the instance since its not a feature\n",
    "        instance = instance.drop([\"Project ID\"])\n",
    "        # Get the explanation\n",
    "        exp = explainer_lime.explain_instance(\n",
    "            data_row=instance,\n",
    "            predict_fn=model.predict_proba,\n",
    "            num_features=num_of_feat\n",
    "        )\n",
    "        # Append exp object to dictionary\n",
    "        exp_objects[project_id] = exp\n",
    "        # Find the feature names as a list\n",
    "        feat_names = instance.keys().to_list()\n",
    "        # Get the explanation as a list of tuples and save\n",
    "        exp_as_list = get_lime_feature_list(exp, feat_names)\n",
    "        exp_as_list_objects[project_id] = exp_as_list\n",
    "        # Save the explanation as a figure\n",
    "        save_lime_explanation(exp, instance_loc, model_name, list_type, project_id, fold)\n",
    "        \n",
    "    return exp_objects, exp_as_list_objects\n",
    "\n",
    "def get_lime_explanation(x_train, x_test, top_instance_loc_list, bottom_instance_loc_list, class_names, mode, model, model_name, fold, num_of_feat):\n",
    "\n",
    "    # take the list of instances and save the explaination of each instance.\n",
    "    # LIME: define the explainer\n",
    "    # Ex: mode = 'classification' or 'regression'\n",
    "    #     class_names = ['0', '1']\n",
    "\n",
    "    categorical_feature_names = x_train.dtypes[x_train.dtypes==bool].index.to_list()\n",
    "    categorical_feature_index = [x_train.columns.get_loc(col) for col in categorical_feature_names]\n",
    "    \n",
    "    # Define the explainer\n",
    "    explainer_lime = lime_tabular.LimeTabularExplainer(\n",
    "        training_data=np.array(x_train),\n",
    "        feature_names=x_train.columns,\n",
    "        categorical_features = categorical_feature_index,\n",
    "        class_names=class_names,\n",
    "        mode=mode\n",
    "    )\n",
    "    \n",
    "    # Get LIME explanations for both top and bottom lists with Project ID\n",
    "    print(\"Top list\")\n",
    "    exp_objects_top, exp_as_list_objects_top = get_lime_for_list(top_instance_loc_list, x_test, explainer_lime, model, model_name, \"top\", fold, num_of_feat)\n",
    "    print(\"Bottom list\")\n",
    "    exp_objects_bottom, exp_as_list_objects_bottom = get_lime_for_list(bottom_instance_loc_list, x_test, explainer_lime, model, model_name, \"bottom\", fold, num_of_feat)\n",
    "    \n",
    "    return exp_as_list_objects_top, exp_as_list_objects_bottom\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442ad73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_treeshap_explanation(explainer_tree, exp, instance, model_name, list_type, project_id, fold):\n",
    "\n",
    "    # Visualize and save\n",
    "    filepath = f'{TREESHAP_DEST}{fold}/{list_type}/treeshap_exp_{project_id}_{model_name}.png'\n",
    "    print(f\"Saving treeshap exp for {filepath}\")\n",
    "    shap.force_plot(explainer_tree.expected_value[1], \n",
    "                exp[1],\n",
    "                instance,\n",
    "                show=False, \n",
    "                matplotlib=True, \n",
    "                text_rotation=45).savefig(filepath, format = \"png\", dpi = 150, bbox_inches = 'tight')\n",
    "    return\n",
    "\n",
    "\n",
    "def get_treeshap_feature_list(exp, feat_names, num_of_feat):\n",
    "    \n",
    "    # Create list of tuples\n",
    "    shap_values = dict(zip(feat_names, exp[1][0]))\n",
    "    sorted_shap_exp = sorted(shap_values.items(), key=lambda x:abs(x[1]), reverse=True)[:num_of_feat]\n",
    "\n",
    "    #exp_list = exp[1].tolist()\n",
    "    #exp_list_with_feature_names = [(feat_names[x], exp_list[x]) for x in range(len(exp_list))]\n",
    "    #print(f'exp_list_with_feature_names = {exp_list_with_feature_names}')\n",
    "    \n",
    "    return sorted_shap_exp\n",
    "\n",
    "\n",
    "# Function to generate explanations for a list of instances\n",
    "def get_treeshap_for_list(instance_loc_list, x_test, explainer_tree, model_name, list_type, fold, num_of_feat):\n",
    "\n",
    "    # Dictionary used to save the explanation objects\n",
    "    exp_objects = {}\n",
    "    exp_as_list_objects = {}\n",
    "    \n",
    "    for i, instance_loc in enumerate(instance_loc_list):\n",
    "        # Select instance\n",
    "        instance = x_test.iloc[[instance_loc]]\n",
    "        # Find its Project ID\n",
    "        project_id = instance[\"Project ID\"].values[0]\n",
    "        # Drop the Project ID value from the instance since its not a feature\n",
    "        instance = instance.drop([\"Project ID\"], axis=1)\n",
    "        # Get the explanation\n",
    "        exp = explainer_tree.shap_values(instance)\n",
    "        #print(f'exp[1] = {exp[1]}')\n",
    "        # Append exp object to dictionary\n",
    "        exp_objects[project_id] = exp\n",
    "        # Find the feature names as a list\n",
    "        feat_names = instance.columns.to_list()\n",
    "        print(f'len(exp[1][0]) = {len(exp[1][0])}')\n",
    "        print(f'len(feat_names) = {len(feat_names)}')\n",
    "        print(f'exp[1][0] = {exp[1][0]}')\n",
    "        print(f'feat_names top {num_of_feat} = {feat_names[:num_of_feat]}')\n",
    "        \n",
    "        # Get the explanation as a list of tuples and save\n",
    "        exp_as_list = get_treeshap_feature_list(exp, feat_names, num_of_feat)\n",
    "        exp_as_list_objects[project_id] = exp_as_list\n",
    "        #print(exp_as_list)\n",
    "        print(f'type(exp_as_list) = {type(exp_as_list)}')\n",
    "        # Save the explanation as a figure\n",
    "        save_treeshap_explanation(explainer_tree, exp, instance, model_name, list_type, project_id, fold)\n",
    "        \n",
    "    return exp_objects, exp_as_list_objects\n",
    "\n",
    "\n",
    "def get_treeshap_explanation(x_train, x_test, top_instance_loc_list, bottom_instance_loc_list, model, model_name, fold, num_of_feat):\n",
    "    \n",
    "#     print(x_train.head())\n",
    "    # Define the KernelSHAP explainer\n",
    "#     explainer_tree = shap.TreeExplainer(model=model, data=x_train, model_output=\"raw\")\n",
    "    print(f\"Treeshap explainer: Start training\")\n",
    "    explainer_tree = shap.TreeExplainer(model=model, feature_perturbation='interventional', data=x_train, model_output=\"raw\")\n",
    "    print(f\"Treeshap explainer: Done training\")\n",
    "    \n",
    "    filepath = f'{TREESHAP_DEST}{fold}/top/'\n",
    "    try:\n",
    "        os.makedirs(filepath, exist_ok = True)\n",
    "        print(\"Directory '%s' created successfully\" %filepath)\n",
    "    except OSError as error:\n",
    "        print(\"Directory '%s' can not be created\")\n",
    "        \n",
    "    filepath = f'{TREESHAP_DEST}{fold}/bottom/'\n",
    "    try:\n",
    "        os.makedirs(filepath, exist_ok = True)\n",
    "        print(\"Directory '%s' created successfully\" %filepath)\n",
    "    except OSError as error:\n",
    "        print(\"Directory '%s' can not be created\")\n",
    "            \n",
    "    print(\"Top list\")          \n",
    "    exp_objects_top, exp_as_list_objects_top = get_treeshap_for_list(top_instance_loc_list, x_test, explainer_tree, model_name, \"top\", fold, num_of_feat)\n",
    "    \n",
    "    print(\"Bottom list\")\n",
    "    exp_objects_bottom, exp_as_list_objects_bottom = get_treeshap_for_list(bottom_instance_loc_list, x_test, explainer_tree, model_name, \"bottom\", fold, num_of_feat)\n",
    "    \n",
    "    return exp_as_list_objects_top, exp_as_list_objects_bottom\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadae52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_kernelshap_explanation(explainer_tree, exp, instance, model_name, list_type, project_id, fold):\n",
    "\n",
    "    # Visualize and save\n",
    "    filepath = f'{SHAP_DEST}{fold}/{list_type}/kernelshap_exp_{project_id}_{model_name}.png'\n",
    "    print(f\"Saving kernelshap exp for {filepath}\")\n",
    "    shap.force_plot(explainer_tree.expected_value[1], \n",
    "                exp[1],\n",
    "                instance,\n",
    "                show=False, \n",
    "                matplotlib=True, \n",
    "                text_rotation=45).savefig(filepath, format = \"png\", dpi = 150, bbox_inches = 'tight')\n",
    "    return\n",
    "\n",
    "def get_kernelshap_feature_list(exp, feat_names, num_of_feat):\n",
    "    \n",
    "    # Create list of tuples\n",
    "    shap_values = dict(zip(feat_names, exp[1]))\n",
    "    sorted_shap_exp = sorted(shap_values.items(), key=lambda x:abs(x[1]), reverse=True)[:num_of_feat]\n",
    "\n",
    "    #exp_list = exp[1].tolist()\n",
    "    #exp_list_with_feature_names = [(feat_names[x], exp_list[x]) for x in range(len(exp_list))]\n",
    "    #print(f'exp_list_with_feature_names = {exp_list_with_feature_names}')\n",
    "    \n",
    "    return sorted_shap_exp\n",
    "\n",
    "\n",
    "# Function to generate explanations for a list of instances\n",
    "def get_kernelshap_for_list(instance_loc_list, x_test, explainer_tree, model_name, list_type, fold, num_of_feat, nsamples):\n",
    "\n",
    "    # Dictionary used to save the explanation objects\n",
    "    exp_objects = {}\n",
    "    exp_as_list_objects = {}\n",
    "    \n",
    "    for i, instance_loc in enumerate(instance_loc_list):\n",
    "        # Select instance\n",
    "        instance = x_test.iloc[instance_loc]\n",
    "        # Find its Project ID\n",
    "        project_id = instance[\"Project ID\"]\n",
    "        # Drop the Project ID value from the instance since its not a feature\n",
    "        instance = instance.drop([\"Project ID\"])\n",
    "        \n",
    "        # Get the explanation\n",
    "        exp = explainer_tree.shap_values(instance, nsamples=nsamples) # nsamples can be either 'auto' or an int\n",
    "        print(f'len(exp[1]) = {len(exp[1])}')\n",
    "        print(f'exp[1] = {exp[1]}')\n",
    "        # Find the feature names as a list\n",
    "        feat_names = instance.keys().to_list()\n",
    "        print(f'len(feat_names) = {len(feat_names)}')\n",
    "        print(f'feat_names top entries = {feat_names[:num_of_feat]}')\n",
    "        \n",
    "        # Append exp object to dictionary\n",
    "        exp_objects[project_id] = exp\n",
    "        # Get the explanation as a list of tuples and save\n",
    "        exp_as_list = get_kernelshap_feature_list(exp, feat_names, num_of_feat)\n",
    "        exp_as_list_objects[project_id] = exp_as_list\n",
    "        \n",
    "        print(f'type(exp_as_list) = {type(exp_as_list)}')\n",
    "        # Save the explanation as a figure\n",
    "        save_kernelshap_explanation(explainer_tree, exp, instance, model_name, list_type, project_id, fold)\n",
    "        \n",
    "    return exp_objects, exp_as_list_objects\n",
    "\n",
    "\n",
    "\n",
    "def get_kernelshap_explanation(x_train, x_test, top_instance_loc_list, bottom_instance_loc_list, model, model_name, fold, num_of_feat, nsamples):\n",
    "    \n",
    "    # Define the KernelSHAP explainer\n",
    "    print(\"Kernel Explainer Loading ..... \")\n",
    "    explainer_shap = shap.KernelExplainer(model=model.predict_proba, data=x_train)\n",
    "    print(\"Kernel Explainer : Done training\")\n",
    "    \n",
    "    filepath = f'{SHAP_DEST}{fold}/top/'\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(filepath, exist_ok = True)\n",
    "        print(\"Directory '%s' created successfully\" %filepath)\n",
    "    except OSError as error:\n",
    "        print(\"Directory '%s' can not be created\")\n",
    "        \n",
    "    filepath = f'{SHAP_DEST}{fold}/bottom/'\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(filepath, exist_ok = True)\n",
    "        print(\"Directory '%s' created successfully\" %filepath)\n",
    "    except OSError as error:\n",
    "        print(\"Directory '%s' can not be created\")\n",
    "            \n",
    "            \n",
    "    print(\"Top list\")    \n",
    "    exp_objects_top, exp_as_list_objects_top = get_kernelshap_for_list(top_instance_loc_list, x_test, explainer_shap, model_name, \"top\", fold, num_of_feat, nsamples)   \n",
    "    print(\"Bottom list\")\n",
    "    exp_objects_bottom, exp_as_list_objects_bottom = get_kernelshap_for_list(bottom_instance_loc_list, x_test, explainer_shap, model_name, \"bottom\", fold, num_of_feat, nsamples)\n",
    "\n",
    "    return exp_as_list_objects_top, exp_as_list_objects_bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68092194-9209-4277-ad7e-fb09d961cc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to create csv using explanations\n",
    "def create_csv_for_exps(feat_names, lime_dict, treeshap_dict, kernelshap_dict, list_type, fold):\n",
    "    # First create an empty df\n",
    "    data = pd.DataFrame()\n",
    "    # Create feature column\n",
    "    data['features'] = feat_names\n",
    "    # Create columns to store lime, treeshap and kernalshap values for each project in the dictionary\n",
    "    projects_list = list(lime_dict.keys())\n",
    "    print(f'Projects list = {projects_list}')\n",
    "    for project in projects_list:\n",
    "        # Create empty columns\n",
    "        data[f'lime_{list_type}_{project}'] = \"\" \n",
    "        data[f'treeshap_{list_type}_{project}'] = \"\"\n",
    "        data[f'kernelshap_{list_type}_{project}'] = \"\"\n",
    "\n",
    "        # Get lime, treeshap and kernelshap lists of tuples\n",
    "        lime_list = lime_dict[project]\n",
    "        treeshap_list = treeshap_dict[project]\n",
    "        kernelshap_list = kernelshap_dict[project]\n",
    "\n",
    "        # Fill the necessary cells with data\n",
    "        # For lime\n",
    "        for item in lime_list:\n",
    "            feature = item[0]\n",
    "            value = item[1]\n",
    "            data.loc[data['features'] == feature, f'lime_{list_type}_{project}'] = value\n",
    "        # For treeshap\n",
    "        for item in treeshap_list:\n",
    "            feature = item[0]\n",
    "            value = item[1]\n",
    "            data.loc[data['features'] == feature, f'treeshap_{list_type}_{project}'] = value\n",
    "        # For kernelshap\n",
    "        for item in kernelshap_list:\n",
    "            feature = item[0]\n",
    "            value = item[1]\n",
    "            data.loc[data['features'] == feature, f'kernelshap_{list_type}_{project}'] = value\n",
    "\n",
    "    \n",
    "    print(data.columns)\n",
    "    # Save as csv\n",
    "    data.to_csv(OUTPUT_DEST+f'all_explanations_{fold}_{list_type}.csv') #### MAKE SURE OUTPUT_DEST IS DEFINED\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2884c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New pipeline for running the explainations - call this from main\n",
    "def explanations_pipeline(root, model_paths, train_paths, test_paths, pred_paths, model_name):\n",
    "  \"\"\"this pipeline will generate explanations for the given model paths\n",
    "\n",
    "  Args:\n",
    "      root (_type_): This is the root path of the model artifacts\n",
    "      model_paths (_type_): these are the paths to the model artifacts\n",
    "      train_paths (_type_): these are the paths to the train artifacts\n",
    "      test_paths (_type_): these are the paths to the test artifacts\n",
    "      pred_paths (_type_): these are the paths to the prediction artifacts\n",
    "      model_name (str): this is the model name as a string for identification. ex: \"random forest\"\n",
    "      \n",
    "      all the artifacts should be a list of files and should be in the same order\n",
    "  \"\"\"\n",
    "  assert len(train_paths) == len(test_paths), \"There should be same number of train paths and test paths\"\n",
    "  assert len(test_paths) == len(pred_paths), \"There should be same number of predictions paths and test paths\"\n",
    "  assert len(model_paths) == len(test_paths), \"There should be same number of model_paths paths and test paths\"\n",
    "\n",
    "  num_of_explanations = 1 # Should be 50 #### CHANGE THE VALUE TO 50\n",
    "  num_of_records = 20 # Should be 1000 #### CHANGE THE VALUE TO 1000\n",
    "  rows = 1000 # Should be None #### CHANGE THE VALUE TO NONE\n",
    "\n",
    "  # Dictionary to store all explanations\n",
    "  all_exp_dict = {}\n",
    "\n",
    "  # Loop to generate explanations for samples from each fold\n",
    "  for i in range(len(train_paths)):\n",
    "    print(f\"Fold {i} .............................\")\n",
    "    x_train = pd.read_csv(os.path.join(root, train_paths[i]), nrows=rows)\n",
    "    x_train_cleaned = x_train.drop([\"Unnamed: 0\", \"Project ID\", \"Label\"], axis=1)\n",
    "\n",
    "    fold1 = pd.read_csv(os.path.join(root,test_paths[i]), nrows=rows)\n",
    "    fold_pred =  pd.read_csv(os.path.join(root,  pred_paths[i]), nrows=rows)\n",
    "    Fold1 = pd.concat([fold1, fold_pred[\"1\"]],axis=1)\n",
    "    Fold1 = Fold1.drop([\"Unnamed: 0\"],axis=1)\n",
    "    Fold1_sort = Fold1.sort_values([\"1\"], ascending=False)\n",
    "    #Fold1_sort.head()\n",
    "    x_test_with_id = Fold1_sort.drop([ \"Label\", \"1\"],axis=1)\n",
    "\n",
    "    # Select n samples each from top and bottom k records\n",
    "    print(f\"Sampling the top {num_of_explanations} and bottom {num_of_explanations}\")\n",
    "    top_instance_loc_list = random.sample(range(num_of_records), num_of_explanations)\n",
    "    bottom_instance_loc_list = random.sample(range(x_test_with_id.shape[0]-num_of_records , x_test_with_id.shape[0]), num_of_explanations)\n",
    "    print(f'top_instance_loc_list = {top_instance_loc_list}')\n",
    "    print(f'bottom_instance_loc_list = {bottom_instance_loc_list}')\n",
    "      \n",
    "    # Define the number of features required to display after generating the explanations\n",
    "    #num_of_feat = x_test_with_id.shape[1] - 1\n",
    "    num_of_feat = 10 #### COMMENT THIS UNCOMMENT THE PREVIOUS LINE\n",
    "    x_train_n_rows = 100 #### CHANGE IF NECESSARY\n",
    "\n",
    "    print(f\"Model {model_paths} is loading\")\n",
    "\n",
    "    # Load the saved model\n",
    "    model = load_model(os.path.join(root, model_paths[i]))\n",
    "\n",
    "    # Get explanations\n",
    "    print(f\"Explanation for Lime\")\n",
    "    lime_list_objects_top, lime_list_objects_bottom = get_lime_explanation(x_train_cleaned[:x_train_n_rows].astype(\"float64\"), x_test_with_id, top_instance_loc_list, bottom_instance_loc_list, [\"0\", \"1\"], \"classification\", model, model_name, f\"Fold{i}\", num_of_feat)\n",
    "    print(f\"Explanation for Kernel Shap\" )\n",
    "    kernelshap_list_objects_top, kernelshap_list_objects_bottom = get_kernelshap_explanation(x_train_cleaned[:x_train_n_rows].astype(\"float64\"), x_test_with_id, top_instance_loc_list, bottom_instance_loc_list, model, model_name, f\"Fold{i}\", num_of_feat, 100) \n",
    "    print(f\"Explanation for Tree Shap\")\n",
    "    treeshap_list_objects_top, treeshap_list_objects_bottom = get_treeshap_explanation(x_train_cleaned[:x_train_n_rows].astype(\"float64\"), x_test_with_id, top_instance_loc_list, bottom_instance_loc_list, model, model_name, f\"Fold{i}\", num_of_feat) \n",
    "\n",
    "    #print(lime_list_objects_top)\n",
    "    #print(treeshap_list_objects_top)\n",
    "    #print(kernelshap_list_objects_top)\n",
    "\n",
    "    # Create dictionaries to store the explanations as json\n",
    "    current_fold_dict = {\n",
    "        'lime': {\n",
    "            'top': lime_list_objects_top,\n",
    "            'bottom': lime_list_objects_bottom\n",
    "        },\n",
    "        'treeshap': {\n",
    "            'top': treeshap_list_objects_top,\n",
    "            'bottom': treeshap_list_objects_bottom\n",
    "        },\n",
    "        'kernelshap': {\n",
    "            'top': kernelshap_list_objects_top,\n",
    "            'bottom': kernelshap_list_objects_bottom\n",
    "        }\n",
    "    }\n",
    "    all_exp_dict[f\"fold{i}\"] = current_fold_dict\n",
    "\n",
    "  # Get a list of all the features\n",
    "  list_of_features = x_test_with_id.drop([\"Project ID\"],axis=1).columns.to_list()\n",
    "  # Storing explanations as json\n",
    "  save_json(all_exp_dict, OUTPUT_DEST+'all_exp.json') #### MAKE SURE OUTPUT_DEST IS DEFINED\n",
    "\n",
    "  # Creating top and bottom csvs for each fold to summarize explanations\n",
    "  for i in range(len(train_paths)):\n",
    "      # For the top list\n",
    "      top_df = create_csv_for_exps(list_of_features, all_exp_dict[f\"fold{i}\"][\"lime\"][\"top\"], all_exp_dict[f\"fold{i}\"][\"treeshap\"][\"top\"], all_exp_dict[f\"fold{i}\"][\"kernelshap\"][\"top\"], \"top\", f\"fold{i}\")\n",
    "      # For the bottom list\n",
    "      bottom_df = create_csv_for_exps(list_of_features, all_exp_dict[f\"fold{i}\"][\"lime\"][\"bottom\"], all_exp_dict[f\"fold{i}\"][\"treeshap\"][\"bottom\"], all_exp_dict[f\"fold{i}\"][\"kernelshap\"][\"bottom\"], \"bottom\", f\"fold{i}\")\n",
    "    \n",
    "  \n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f472d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations_pipeline(root, models, train_files, test_files, test_pred, \"random_forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb2a72b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
