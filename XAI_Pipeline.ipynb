{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bded8452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32abd836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import lime\n",
    "from lime import lime_tabular\n",
    "import shap\n",
    "\n",
    "import json\n",
    "from typing import Union\n",
    "from datetime import datetime as dt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36ddedc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/storage/scratch/e17-4yp-xai/Documents/artefact_backup/backup_1M_inputs_rand_frst/model_outputs/artifacts/random_forest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f705e35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = sorted(['train_fold_1_2017-01-06.csv', 'train_fold_2_2016-09-08.csv', 'train_fold_3_2016-05-11.csv', 'train_fold_4_2016-01-12.csv', 'train_fold_5_2015-09-14.csv' , 'train_fold_6_2015-05-17.csv'], reverse=True)\n",
    "test_files = [ 'test_fold_6_2015-05-17.csv' , 'test_fold_5_2015-09-14.csv', 'test_fold_4_2016-01-12.csv', 'test_fold_3_2016-05-11.csv',  'test_fold_2_2016-09-08.csv', 'test_fold_1_2017-01-06.csv']\n",
    "\n",
    "\n",
    "test_pred = ['test_prediction_fold_6_2015-05-17.csv' , 'test_prediction_fold_5_2015-09-14.csv', 'test_prediction_fold_4_2016-01-12.csv', 'test_prediction_fold_3_2016-05-11.csv', 'test_prediction_fold_2_2016-09-08.csv' , 'test_prediction_fold_1_2017-01-06.csv' ]\n",
    "\n",
    "models = sorted([\"random_forest_fold_1_2017-01-06.pkl\", \"random_forest_fold_2_2016-09-08.pkl\", \"random_forest_fold_3_2016-05-11.pkl\", \"random_forest_fold_4_2016-01-12.pkl\", \"random_forest_fold_5_2015-09-14.pkl\", \"random_forest_fold_6_2015-05-17.pkl\" ], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34a691e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ROOT = \"/storage/scratch/e17-4yp-xai/Documents/e17-4yp-using-machine-learning-in-high-stake-settings/code/\"\n",
    "ROOT = \"./\"\n",
    "DATA_SOURCE = ROOT + \"data/DsDnsPrScTch.csv\"\n",
    "DATA_DEST = ROOT + \"processed_data/\"\n",
    "MODEL_DEST = ROOT + \"trained_models/\"\n",
    "IMAGE_DEST = ROOT + \"model_outputs/figures/\"\n",
    "LIME_DEST = ROOT + \"model_outputs/lime/\"\n",
    "SHAP_DEST = ROOT + \"model_outputs/shap/\"\n",
    "TREESHAP_DEST = ROOT + \"model_outputs/treeshap/\"\n",
    "K_PROJECTS_DEST = IMAGE_DEST + \"k_projects/\"\n",
    "ROC_CURVE_DEST = IMAGE_DEST + \"roc_curve/\"\n",
    "P_VS_R_CURVE_DEST = IMAGE_DEST + \"pr_curve/\"\n",
    "ARTIFACTS_PATH = ROOT + \"model_outputs/artifacts/\"\n",
    "\n",
    "INFO_DEST = ROOT+\"model_outputs/info/\"\n",
    "# MODEL_RUN_LOG_PATH = INFO_DEST + \"model_run_log.py\"\n",
    "PROCESSED_DATA_PATH = DATA_DEST + \"labelled_final_data.csv\"\n",
    "\n",
    "LOAD_PROCESSED_DATA_FLAG = False\n",
    "MAX_ROWS = 400000  # if you change this, updating LOAD_PROCESSED_DATA_FLAG to False is required\n",
    "\n",
    "FIXED_KVAL = 1000\n",
    "\n",
    "# To label data\n",
    "DONATION_PERIOD = 30\n",
    "THRESHOLD_RATIO = 0.4\n",
    "\n",
    "TRAINING_WINDOW = DONATION_PERIOD * 4\n",
    "\n",
    "MAX_TIME = \"2016-04-01 00:00:00\"\n",
    "MIN_TIME = \"2013-05-01 00:00:00\"\n",
    "\n",
    "TEST_SIZE = 30\n",
    "TRAIN_SIZE = TEST_SIZE*6\n",
    "LEAK_OFFSET = TEST_SIZE*4\n",
    "WINDOW = TEST_SIZE + TRAIN_SIZE + 2*LEAK_OFFSET\n",
    "\n",
    "\n",
    "DATE_COLS = [\"Teacher First Project Posted Date\", \"Project Fully Funded Date\", \"Project Expiration Date\",\n",
    "             \"Project Posted Date\", \"Donation Received Date\"]\n",
    "CATEGORICAL_COLS = [\"Project Type\", \"Project Subject Category Tree\", \"Project Subject Subcategory Tree\",\n",
    "                    \"Project Grade Level Category\", \"Project Resource Category\", \"School Metro Type\",\n",
    "                    \"School State\", \"School County\", \"Teacher Prefix\", \"School Name\", \"School City\", \"School District\"]\n",
    "\n",
    "TRAINING_FEATURES = [\"Project ID\", \"Project Posted Date\", \"Project Type\", \"Project Subject Category Tree\", \"Project Cost\",\n",
    "                     \"Project Subject Subcategory Tree\", \"Project Grade Level Category\", \"Project Resource Category\",\n",
    "                     \"School Metro Type\", \"School Percentage Free Lunch\", \"School State\", \"School County\",\n",
    "                     \"School Name\", \"School City\", \"School District\",\n",
    "                     \"Teacher Prefix\", \"Teacher Project Posted Sequence\"]\n",
    "#   \"Statement Error Ratio\", \"Title Essay Relativity\", \"Description Essay Relativity\"]\n",
    "\n",
    "VARIABLES_TO_SCALE = [\"School Percentage Free Lunch\", \"Teacher Project Posted Sequence\", \"Project Cost\",\n",
    "                      'Teacher Success Rate', 'School City Success Rate', 'School Success Rate',\n",
    "                      'School County Success Rate', 'Project Count in State']\n",
    "# \"Statement Error Ratio\", \"Title Essay Relativity\", \"Description Essay Relativity\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32dfaad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def save_model(path, file_name, model):\n",
    "    file_path = path + file_name\n",
    "    pickle.dump(model, file=open(file_path, \"wb\"))\n",
    "\n",
    "\n",
    "def load_model(model_file_path):\n",
    "    return pickle.load(open(model_file_path, 'rb'))\n",
    "\n",
    "def log_intermediate_output_to_file(path, file_name, log_info: Union[list, dict, str]):\n",
    "    file_path = path + file_name\n",
    "    json_data = json.dumps(log_info, indent=2)\n",
    "    time = dt.now()\n",
    "    with open(file_path, 'a') as file:\n",
    "        file.write(f\"\\nlog {str(time.strftime('%Y-%m-%d %H:%M:%S'))}\\n{json_data}\\n\")\n",
    "\n",
    "\n",
    "def create_dirs(models=None):\n",
    "    if not models:\n",
    "        models = ['decision_tree', 'log_reg', 'random_forest', 'svm']\n",
    "    paths = [\n",
    "        config.ARTIFACTS_PATH+model_dir+'/' for model_dir in models\n",
    "    ] + [\n",
    "        config.IMAGE_DEST+model_dir+'/' for model_dir in models\n",
    "    ] + [\n",
    "        config.IMAGE_DEST+'k_projects/'+model_dir+'/' for model_dir in models\n",
    "    ] + [\n",
    "        config.INFO_DEST+model_dir+'/' for model_dir in models\n",
    "    ] + [\n",
    "        config.ROOT+'trained_models/', config.ROOT+'processed_data/'\n",
    "    ]\n",
    "    for path in paths:\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "    print(f\"{len(paths)} directories created...\")\n",
    "    print('Created all directories!')\n",
    "\n",
    "\n",
    "def create_random_forest_parameters(\n",
    "    max_depths=[2, 3],\n",
    "    n_estimators=[20, 100],\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=2,\n",
    ") -> list:\n",
    "    parameters_list = []\n",
    "    # create various combinations of the above attributes\n",
    "    for max_depth in max_depths:\n",
    "        for n in n_estimators:\n",
    "            parameters = {\n",
    "                'criterion': \"gini\",\n",
    "                'max_depth': max_depth,\n",
    "                'n_estimators': n,\n",
    "                'min_samples_split': min_samples_split,\n",
    "                'min_samples_leaf': min_samples_leaf\n",
    "            }\n",
    "            parameters_list.append(parameters)\n",
    "    return parameters_list\n",
    "\n",
    "\n",
    "def create_logistic_regression_parameters(\n",
    "        solver=\"saga\",\n",
    "        max_iters=[100, 200],\n",
    "        penalties=[\"l1\", \"l2\"]\n",
    ") -> list:\n",
    "    parameters_list = []\n",
    "    for penalty in penalties:\n",
    "        for max_iter in max_iters:\n",
    "            parameters = {\n",
    "                'penalty': penalty,\n",
    "                'solver': solver,\n",
    "                'max_iter': max_iter\n",
    "            }\n",
    "            parameters_list.append(parameters)\n",
    "\n",
    "    return parameters_list\n",
    "\n",
    "\n",
    "def create_classification_models(\n",
    "        random_forest_parameters_list: list,\n",
    "        logistic_regression_parameters_list: list\n",
    ") -> list:\n",
    "    models_list = []\n",
    "    i = 1\n",
    "    for parameters in random_forest_parameters_list:\n",
    "        new_model = RandomForestClassifier(**parameters)\n",
    "        models_list.append({\n",
    "            'model_name': f'random_forest_{i}',\n",
    "            'model': new_model,\n",
    "            'type': 'non-linear',\n",
    "            'parameters': parameters\n",
    "        })\n",
    "        i += 1\n",
    "\n",
    "    i = 1\n",
    "    for parameters in logistic_regression_parameters_list:\n",
    "        new_model = LogisticRegression(**parameters)\n",
    "        models_list.append({\n",
    "            'model_name': f'logistic_regression_{i}',\n",
    "            'model': new_model,\n",
    "            'type': 'linear',\n",
    "            'parameters': parameters\n",
    "        })\n",
    "        i += 1\n",
    "    cost_sorted_k_baseline_model = {\n",
    "        'model_name': 'cost_sorted_k_baseline_model',\n",
    "        'model': None,\n",
    "        'type': 'baseline'\n",
    "    }\n",
    "    random_k_baseline_model = {\n",
    "        'model_name': 'random_k_baseline_model',\n",
    "        'model': None,\n",
    "        'type': 'baseline'\n",
    "    }\n",
    "    models_list.append(cost_sorted_k_baseline_model)\n",
    "    models_list.append(random_k_baseline_model)\n",
    "\n",
    "    return models_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ef2a8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def save_lime_explanation(exp, instance_loc, model_name, position, project_id,fold):\n",
    "\n",
    "    # exp.show_in_notebook(show_table=True)\n",
    "    # Save as html file\n",
    "    filepath = f\"{LIME_DEST}{fold}/{position}\"\n",
    "    try:\n",
    "        os.makedirs(filepath, exist_ok = True)\n",
    "        print(\"Directory '%s' created successfully\" %filepath)\n",
    "    except OSError as error:\n",
    "        print(\"Directory '%s' can not be created\")\n",
    "    \n",
    "    exp.save_to_file(f'{LIME_DEST}{fold}/{position}/lime_exp_{project_id}_{model_name}.html')\n",
    "\n",
    "    # Save as pyplot figure\n",
    "    plt.cla()\n",
    "    exp.as_pyplot_figure()\n",
    "    plt.savefig(f'{LIME_DEST}{fold}/{position}/lime_exp_{project_id}_{model_name}.png')\n",
    "    plt.show()\n",
    "\n",
    "    return\n",
    "\n",
    "def get_lime_explanation(x_train, x_test, top_instance_loc_list, bottom_instance_loc_list, class_names, mode, model, model_name, fold):\n",
    "\n",
    "    # take the list of instances and save the explaination of each instance.\n",
    "    # LIME: define the explainer\n",
    "    # Ex: mode = 'classification' or 'regression'\n",
    "    #     class_names = ['0', '1']\n",
    "\n",
    "    categorical_feature_names = x_train.dtypes[x_train.dtypes==bool].index.to_list()\n",
    "    categorical_feature_index = [x_train.columns.get_loc(col) for col in categorical_feature_names]\n",
    "    \n",
    "    \n",
    "    explainer_lime = lime_tabular.LimeTabularExplainer(\n",
    "        training_data=np.array(x_train),\n",
    "        feature_names=x_train.columns,\n",
    "        categorical_features = categorical_feature_index,\n",
    "        class_names=class_names,\n",
    "        mode=mode\n",
    "    )\n",
    "    \n",
    "    \n",
    "    for instance_loc in top_instance_loc_list:\n",
    "        # Select instance\n",
    "        instance = x_test.iloc[instance_loc]\n",
    "        # Find its Project ID\n",
    "        project_id = instance[\"Project ID\"]\n",
    "        # Drop the Project ID value from the instance since its not a feature\n",
    "        instance = instance.drop([\"Project ID\"])\n",
    "        # Get the explanation\n",
    "        exp1 = explainer_lime.explain_instance(\n",
    "            data_row=instance,\n",
    "            predict_fn=model.predict_proba\n",
    "        )\n",
    "        # Save the explanation as a figure\n",
    "        save_lime_explanation(exp1, instance_loc, model_name, \"top\", project_id, fold)\n",
    "        \n",
    "    for instance_loc in bottom_instance_loc_list:\n",
    "        # Select instance \n",
    "        instance = x_test.iloc[instance_loc]\n",
    "        # Find its Project ID\n",
    "        project_id = instance[\"Project ID\"]\n",
    "        # Drop the Project ID value from the instance since its not a feature\n",
    "        instance = instance.drop([\"Project ID\"])\n",
    "        # Get the explanation\n",
    "        exp2 = explainer_lime.explain_instance(\n",
    "            data_row=instance,\n",
    "            predict_fn=model.predict_proba\n",
    "        )\n",
    "        # Save the explanation as a figure\n",
    "        save_lime_explanation(exp2, instance_loc, model_name, \"bottom\", project_id, fold)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "deadae52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_shap_explanation(x_train, x_test, top_instance_loc_list, bottom_instance_loc_list, model, model_name, fold):\n",
    "    \n",
    "    # Define the KernelSHAP explainer\n",
    "    explainer_shap = shap.KernelExplainer(model=model.predict_proba, data=x_train)\n",
    "\n",
    "\n",
    "    for instance_loc in top_instance_loc_list:\n",
    "        # Select instance\n",
    "        instance = x_test.iloc[instance_loc]\n",
    "        # Find its Project ID\n",
    "        project_id = instance[\"Project ID\"]\n",
    "        # Drop the Project ID value from the instance since its not a feature\n",
    "        instance = instance.drop([\"Project ID\"])\n",
    "        # Find the explanation\n",
    "        shap_values = explainer_shap.shap_values(instance)\n",
    "\n",
    "        # Visualize and save\n",
    "        # Can be either 0 or 1 for binary classification\n",
    "        #shap.force_plot(explainer_shap.expected_value[0], shap_values[0], instance)\n",
    "        filepath = f'{SHAP_DEST}{fold}/top/shap_exp_{project_id}_{model_name}.png'\n",
    "        try:\n",
    "            os.makedirs(filepath, exist_ok = True)\n",
    "            print(\"Directory '%s' created successfully\" %filepath)\n",
    "        except OSError as error:\n",
    "            print(\"Directory '%s' can not be created\")\n",
    "        shap.force_plot(explainer_shap.expected_value[0], \n",
    "                        shap_values[0], \n",
    "                        instance, \n",
    "                        show=False, \n",
    "                        matplotlib=True, \n",
    "                        text_rotation=45).savefig(filepath, format = \"png\", dpi = 150, bbox_inches = 'tight') \n",
    "        \n",
    "    for instance_loc in bottom_instance_loc_list:\n",
    "        # Select instance\n",
    "        instance = x_test.iloc[instance_loc]\n",
    "        # Find its Project ID\n",
    "        project_id = instance[\"Project ID\"]\n",
    "        # Drop the Project ID value from the instance since its not a feature\n",
    "        instance = instance.drop([\"Project ID\"])\n",
    "        # Find the explanation\n",
    "        shap_values = explainer_shap.shap_values(instance)\n",
    "\n",
    "        # Visualize and save\n",
    "        # Can be either 0 or 1 for binary classification\n",
    "        #shap.force_plot(explainer_shap.expected_value[0], shap_values[0], instance)\n",
    "        filepath = f'{SHAP_DEST}{fold}/bottom/shap_exp_{project_id}_{model_name}.png'\n",
    "        try:\n",
    "            os.makedirs(filepath, exist_ok = True)\n",
    "            print(\"Directory '%s' created successfully\" %filepath)\n",
    "        except OSError as error:\n",
    "            print(\"Directory '%s' can not be created\")\n",
    "        shap.force_plot(explainer_shap.expected_value[0], \n",
    "                        shap_values[0], \n",
    "                        instance, \n",
    "                        show=False, \n",
    "                        matplotlib=True, \n",
    "                        text_rotation=45).savefig(filepath, format = \"png\", dpi = 150, bbox_inches = 'tight') \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "442ad73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_treeshap_explanation(x_train, x_test, top_instance_loc_list, bottom_instance_loc_list, model, model_name, fold):\n",
    "    \n",
    "#     print(x_train.head())\n",
    "    # Define the KernelSHAP explainer\n",
    "#     explainer_tree = shap.TreeExplainer(model=model, data=x_train, model_output=\"raw\")\n",
    "    explainer_tree = shap.TreeExplainer(model=model, feature_perturbation='tree_path_dependant')\n",
    "\n",
    "    for instance_loc in top_instance_loc_list:\n",
    "        # Select instance\n",
    "        instance = x_test.iloc[[instance_loc]]\n",
    "        # Find its Project ID\n",
    "        project_id = instance[\"Project ID\"]\n",
    "        # Drop the Project ID value from the instance since its not a feature\n",
    "        instance = instance.drop([\"Project ID\"], axis=1)\n",
    "        # Find the explanation\n",
    "        treeshap_values = explainer_tree.shap_values(instance)\n",
    "\n",
    "        # Visualize and save\n",
    "        filepath = f'{TREESHAP_DEST}{fold}/top/treeshap_exp_{project_id}_{model_name}.png'\n",
    "        shap.force_plot(explainer_tree.expected_value[0], \n",
    "                    treeshap_values[0],\n",
    "                    instance,\n",
    "                    show=False, \n",
    "                    matplotlib=True, \n",
    "                    text_rotation=45).savefig(filepath, format = \"png\", dpi = 150, bbox_inches = 'tight')\n",
    "        \n",
    "    \n",
    "    for instance_loc in bottom_instance_loc_list:\n",
    "        # Select instance\n",
    "        instance = x_test.iloc[instance_loc]\n",
    "        # Find its Project ID\n",
    "        project_id = instance[\"Project ID\"]\n",
    "        # Drop the Project ID value from the instance since its not a feature\n",
    "        instance = instance.drop([\"Project ID\"])\n",
    "        # Find the explanation\n",
    "        treeshap_values = explainer_tree.shap_values(instance)\n",
    "\n",
    "        # Visualize and save\n",
    "        filepath = f'{TREESHAP_DEST}{fold}/bottom/treeshap_exp_{project_id}_{model_name}.png'\n",
    "        try:\n",
    "            os.makedirs(filepath, exist_ok = True)\n",
    "            print(\"Directory '%s' created successfully\" %filepath)\n",
    "        except OSError as error:\n",
    "            print(\"Directory '%s' can not be created\")\n",
    "            \n",
    "        shap.force_plot(explainer_tree.expected_value[0], \n",
    "                    treeshap_values[0],\n",
    "                    instance,\n",
    "                    show=False, \n",
    "                    matplotlib=True, \n",
    "                    text_rotation=45).savefig(filepath, format = \"png\", dpi = 150, bbox_inches = 'tight')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a2884c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "# New pipeline for ruinning the explainations - call this from main\n",
    "def explanations_pipeline(root, model_paths, train_paths, test_paths, pred_paths, model_name):\n",
    "  \"\"\"this pipeline will generate explanations for the given model paths\n",
    "\n",
    "  Args:\n",
    "      root (_type_): This is the root path of the model artifacts\n",
    "      model_paths (_type_): these are the paths to the model artifacts\n",
    "      train_paths (_type_): these are the paths to the train artifacts\n",
    "      test_paths (_type_): these are the paths to the test artifacts\n",
    "      pred_paths (_type_): these are the paths to the prediction artifacts\n",
    "      model_name (str): this is the model name as a string for identification. ex: \"random forest\"\n",
    "      \n",
    "      all the artifacts should be a list of files and should be in the same order\n",
    "  \"\"\"\n",
    "  assert len(train_paths) == len(test_paths), \"There should be same number of train paths and test paths\"\n",
    "  assert len(test_paths) == len(pred_paths), \"There should be same number of predictions paths and test paths\"\n",
    "  assert len(model_paths) == len(test_paths), \"There should be same number of model_paths paths and test paths\"\n",
    "  \n",
    "  for i in range(len(train_paths)):\n",
    "    print(f\"Fold {i} .............................\")\n",
    "    x_train = pd.read_csv(os.path.join(root, train_paths[i]))\n",
    "    x_train_cleaned = x_train.drop([\"Unnamed: 0\", \"Project ID\", \"Label\"], axis=1)\n",
    "\n",
    "    fold1 = pd.read_csv(os.path.join(root,test_paths[i]))\n",
    "    fold_pred =  pd.read_csv(os.path.join(root,  pred_paths[i]))\n",
    "    Fold1 = pd.concat([fold1, fold_pred[\"1\"]],axis=1)\n",
    "    Fold1 = Fold1.drop([\"Unnamed: 0\"],axis=1)\n",
    "    Fold1_sort = Fold1.sort_values([\"1\"], ascending=False)\n",
    "    #Fold1_sort.head()\n",
    "    x_test_with_id = Fold1_sort.drop([ \"Label\", \"1\"],axis=1)\n",
    "\n",
    "    # Select 50 samples each from top and bottom 1000 records\n",
    "    print(\"Sampling the top 50 and bottom 50\")\n",
    "    top_instance_loc_list = random.sample(range(1000), 50)\n",
    "    bottom_instance_loc_list = random.sample(range(x_test_with_id.shape[0]-1000 , x_test_with_id.shape[0]), 50)\n",
    "    # Get the project IDs of those selected records\n",
    "    #top_project_ids = [x_test_with_id._get_value(i, \"Project ID\") for i in top_instance_loc_list]\n",
    "    #bottom_project_ids = [x_test_with_id._get_value(i, \"Project ID\") for i in bottom_instance_loc_list]\n",
    "\n",
    "    # Drop the project ID column\n",
    "    #x_test = x_test_with_id.drop([\"Project ID\"], axis=1)\n",
    "\n",
    "    print(f\"Model {model_paths} is loading\" )\n",
    "\n",
    "    # Load the saved model\n",
    "    model = load_model(os.path.join(root, model_paths[i]))\n",
    "\n",
    "    print(f\"Explanation for  Lime\" )\n",
    "    # Get explanations\n",
    "    #get_lime_explanation(x_train_cleaned[:100], x_test_with_id, top_instance_loc_list, bottom_instance_loc_list, [\"0\", \"1\"], \"classification\", model, model_name)\n",
    "    #print(f\"Explanation for  Kernal Shap\" )\n",
    "    #get_shap_explanation(x_train_cleaned[:100], x_test_with_id, top_instance_loc_list, bottom_instance_loc_list, model, model_name) \n",
    "    print(f\"Explanation for  Tree Shap\" )\n",
    "    get_treeshap_explanation(x_train_cleaned[:100], x_test_with_id, top_instance_loc_list, bottom_instance_loc_list, model, model_name) \n",
    "  \n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f6393995",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 .............................\n",
      "Sampling the top 50 and bottom 50\n",
      "Model ['random_forest_fold_6_2015-05-17.pkl', 'random_forest_fold_5_2015-09-14.pkl', 'random_forest_fold_4_2016-01-12.pkl', 'random_forest_fold_3_2016-05-11.pkl', 'random_forest_fold_2_2016-09-08.pkl', 'random_forest_fold_1_2017-01-06.pkl'] is loading\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trying to unpickle estimator DecisionTreeClassifier from version 1.2.2 when using version 1.2.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "Trying to unpickle estimator RandomForestClassifier from version 1.2.2 when using version 1.2.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation for  Lime\n",
      "Explanation for  Tree Shap\n"
     ]
    },
    {
     "ename": "ExplainerError",
     "evalue": "Additivity check failed in TreeExplainer! Please ensure the data matrix you passed to the explainer is the same shape that the model was trained on. If your data shape is correct then please report this on GitHub. Consider retrying with the feature_perturbation='interventional' option. This check failed because for one of the samples the sum of the SHAP values was 4779698862368309893058651656826205312540209684224990038162333638002771506398391861841551640263116263960162027537119390340218880.000000, while the model output was 0.222000. If this difference is acceptable you can set check_additivity=False to disable this check.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mExplainerError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mexplanations_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrandom_forest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[38], line 58\u001b[0m, in \u001b[0;36mexplanations_pipeline\u001b[0;34m(root, model_paths, train_paths, test_paths, pred_paths, model_name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;66;03m# Get explanations\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   \u001b[38;5;66;03m#get_lime_explanation(x_train_cleaned[:100], x_test_with_id, top_instance_loc_list, bottom_instance_loc_list, [\"0\", \"1\"], \"classification\", model, model_name)\u001b[39;00m\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;66;03m#print(f\"Explanation for  Kernal Shap\" )\u001b[39;00m\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;66;03m#get_shap_explanation(x_train_cleaned[:100], x_test_with_id, top_instance_loc_list, bottom_instance_loc_list, model, model_name) \u001b[39;00m\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExplanation for  Tree Shap\u001b[39m\u001b[38;5;124m\"\u001b[39m )\n\u001b[0;32m---> 58\u001b[0m   \u001b[43mget_treeshap_explanation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_cleaned\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test_with_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_instance_loc_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbottom_instance_loc_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[37], line 16\u001b[0m, in \u001b[0;36mget_treeshap_explanation\u001b[0;34m(x_train, x_test, top_instance_loc_list, bottom_instance_loc_list, model, model_name)\u001b[0m\n\u001b[1;32m     14\u001b[0m instance \u001b[38;5;241m=\u001b[39m instance\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProject ID\u001b[39m\u001b[38;5;124m\"\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Find the explanation\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m treeshap_values \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer_tree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Visualize and save\u001b[39;00m\n\u001b[1;32m     19\u001b[0m filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTREESHAP_DEST\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mtop/treeshap_exp_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproject_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/shap/explainers/_tree.py:442\u001b[0m, in \u001b[0;36mTree.shap_values\u001b[0;34m(self, X, y, tree_limit, approximate, check_additivity, from_call)\u001b[0m\n\u001b[1;32m    440\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_shap_output(phi, flat_output)\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_additivity \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel_output \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 442\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_additivity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/shap/explainers/_tree.py:573\u001b[0m, in \u001b[0;36mTree.assert_additivity\u001b[0;34m(self, phi, model_output)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(phi) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(phi)):\n\u001b[0;32m--> 573\u001b[0m         \u001b[43mcheck_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpected_value\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mphi\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    575\u001b[0m     check_sum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpected_value \u001b[38;5;241m+\u001b[39m phi\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), model_output)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/shap/explainers/_tree.py:569\u001b[0m, in \u001b[0;36mTree.assert_additivity.<locals>.check_sum\u001b[0;34m(sum_val, model_output)\u001b[0m\n\u001b[1;32m    565\u001b[0m     err_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Consider retrying with the feature_perturbation=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minterventional\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m option.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    566\u001b[0m err_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m This check failed because for one of the samples the sum of the SHAP values\u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m    567\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m was \u001b[39m\u001b[38;5;132;01m{:f}\u001b[39;00m\u001b[38;5;124m, while the model output was \u001b[39m\u001b[38;5;132;01m{:f}\u001b[39;00m\u001b[38;5;124m. If this difference is acceptable\u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m    568\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m you can set check_additivity=False to disable this check.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(sum_val[ind], model_output[ind])\n\u001b[0;32m--> 569\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ExplainerError(err_msg)\n",
      "\u001b[0;31mExplainerError\u001b[0m: Additivity check failed in TreeExplainer! Please ensure the data matrix you passed to the explainer is the same shape that the model was trained on. If your data shape is correct then please report this on GitHub. Consider retrying with the feature_perturbation='interventional' option. This check failed because for one of the samples the sum of the SHAP values was 4779698862368309893058651656826205312540209684224990038162333638002771506398391861841551640263116263960162027537119390340218880.000000, while the model output was 0.222000. If this difference is acceptable you can set check_additivity=False to disable this check."
     ]
    }
   ],
   "source": [
    "explanations_pipeline(root, models, train_files, test_files, test_pred, \"random_forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3cbd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf991e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Fold {i} .............................\")\n",
    "x_train = pd.read_csv(os.path.join(root, train_paths[0]))\n",
    "x_train_cleaned = x_train.drop([\"Unnamed: 0\", \"Project ID\", \"Label\"], axis=1)\n",
    "\n",
    "fold1 = pd.read_csv(os.path.join(root,test_paths[i]))\n",
    "fold_pred =  pd.read_csv(os.path.join(root,  pred_paths[0]))\n",
    "Fold1 = pd.concat([fold1, fold_pred[\"1\"]],axis=1)\n",
    "Fold1 = Fold1.drop([\"Unnamed: 0\"],axis=1)\n",
    "Fold1_sort = Fold1.sort_values([\"1\"], ascending=False)\n",
    "#Fold1_sort.head()\n",
    "x_test_with_id = Fold1_sort.drop([ \"Label\", \"1\"],axis=1)\n",
    "\n",
    "# Select 50 samples each from top and bottom 1000 records\n",
    "print(\"Sampling the top 50 and bottom 50\")\n",
    "top_instance_loc_list = random.sample(range(1000), 50)\n",
    "bottom_instance_loc_list = random.sample(range(x_test_with_id.shape[0]-1000 , x_test_with_id.shape[0]), 50)\n",
    "# Get the project IDs of those selected records\n",
    "#top_project_ids = [x_test_with_id._get_value(i, \"Project ID\") for i in top_instance_loc_list]\n",
    "#bottom_project_ids = [x_test_with_id._get_value(i, \"Project ID\") for i in bottom_instance_loc_list]\n",
    "\n",
    "# Drop the project ID column\n",
    "#x_test = x_test_with_id.drop([\"Project ID\"], axis=1)\n",
    "\n",
    "print(f\"Model {model_paths} is loading\" )\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model(os.path.join(root, model_paths[i]))\n",
    "\n",
    "print(f\"Explanation for  Lime\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a557afd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "#     print(x_train.head())\n",
    "    # Define the KernelSHAP explainer\n",
    "#     explainer_tree = shap.TreeExplainer(model=model, data=x_train, model_output=\"raw\")\n",
    "    explainer_tree = shap.TreeExplainer(model=model, feature_perturbation='tree_path_dependant')\n",
    "\n",
    "    for instance_loc in top_instance_loc_list:\n",
    "        # Select instance\n",
    "        instance = x_test.iloc[[instance_loc]]\n",
    "        # Find its Project ID\n",
    "        project_id = instance[\"Project ID\"]\n",
    "        # Drop the Project ID value from the instance since its not a feature\n",
    "        instance = instance.drop([\"Project ID\"], axis=1)\n",
    "        # Find the explanation\n",
    "        treeshap_values = explainer_tree.shap_values(instance)\n",
    "\n",
    "        # Visualize and save\n",
    "        filepath = f'{TREESHAP_DEST}{fold}/top/treeshap_exp_{project_id}_{model_name}.png'\n",
    "        shap.force_plot(explainer_tree.expected_value[0], \n",
    "                    treeshap_values[0],\n",
    "                    instance,\n",
    "                    show=False, \n",
    "                    matplotlib=True, \n",
    "                    text_rotation=45).savefig(filepath, format = \"png\", dpi = 150, bbox_inches = 'tight')\n",
    "        \n",
    "    \n",
    "    for instance_loc in bottom_instance_loc_list:\n",
    "        # Select instance\n",
    "        instance = x_test.iloc[instance_loc]\n",
    "        # Find its Project ID\n",
    "        project_id = instance[\"Project ID\"]\n",
    "        # Drop the Project ID value from the instance since its not a feature\n",
    "        instance = instance.drop([\"Project ID\"])\n",
    "        # Find the explanation\n",
    "        treeshap_values = explainer_tree.shap_values(instance)\n",
    "\n",
    "        # Visualize and save\n",
    "        filepath = f'{TREESHAP_DEST}{fold}/bottom/treeshap_exp_{project_id}_{model_name}.png'\n",
    "        try:\n",
    "            os.makedirs(filepath, exist_ok = True)\n",
    "            print(\"Directory '%s' created successfully\" %filepath)\n",
    "        except OSError as error:\n",
    "            print(\"Directory '%s' can not be created\")\n",
    "            \n",
    "        shap.force_plot(explainer_tree.expected_value[0], \n",
    "                    treeshap_values[0],\n",
    "                    instance,\n",
    "                    show=False, \n",
    "                    matplotlib=True, \n",
    "                    text_rotation=45).savefig(filepath, format = \"png\", dpi = 150, bbox_inches = 'tight')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
